{"posts":[{"title":"monorepo结构下启动react项目局部热更新","text":"基础知识 遇到的问题 问题原因&amp;分析 如何解决问题？ 多子项目单独开发时，如何确定react版本，以及如何保证主项目加载子项目作为组件时，二者公用同一个react实例 开发时，如何处理互相存在依赖子系统 外置化加载react&amp;react-dom时，hot-reload失效 基础知识# 阅读之前你需要知道的知识包括 什么是monorepo monorepo的一些应用场景 webpack的配置的编写 什么是pnpm 遇到的问题# 多子项目单独开发时，如何确定react版本？ 如何保证主项目加载子项目作为组件时，二者公用同一个react实例？ 开发时，如何处理互相存在依赖子系统？ 外置化加载react&amp;react-dom时，hot-reload失效 问题原因&amp;分析# 为什么会引入问题[1]：这是因为使用用monorepo这个结构时，我们希望所有的子系统和主系统(系统的入口)，使用同一个react版本，以便系统整体的核心依赖的控制，并且减少多版本兼容带来的额外的bug。 为什么会引入问题[2]： hooks的使用要求二者必须使用的是一个react实例 对于context，它的使用也依赖于同一react实例 为什么会引入问题[3]：当我们同时满足问题[1]和[2]时，react和react-dom将不能被打包到一个bandle包中，所以在webpack层面，我们需要使用external，排除react。与此同时，由于主流的用于处理react热更新的插件，react-refresh-webpack-plugin对于外置加载的react core有严格的顺序要求，所以导致了热更新的失效 如何解决问题？# 多子项目单独开发时，如何确定react版本，以及如何保证主项目加载子项目作为组件时，二者公用同一个react实例# 我们期待所有这个系统中，所有项目的react依赖都指向同一个react core文件，这样在系统所有项目都构建完成后，react的版本就确定了下来，所以我们可以修改webpack.config.js和项目的HTML模版来达到这个目标： 对于webpack.config.js增加： 12345{ //... external: ['react','react-dom'] //...} 对于HTML模版（这里的具体语法，需要根据具体使用的模版解析器语法来）： 12&lt;script data-tn=&quot;react-bundle&quot; type=&quot;text/javascript&quot; src=&quot;{{reactBundlePath | safe}}&quot;&gt;&lt;script&gt;&lt;script data-tn=&quot;react-dom-bundle&quot; type=&quot;text/javascript&quot; src=&quot;{{reactDomBundlePath | safe&quot;&gt;&lt;/script&gt; 这里的 reactBundlePath 和 reactDomBundlePath是react单独编译后的结果，对应的是两个js文件。 至此react core就完成外置化，所有的子项目在单独开发时，都可以修改自己的HTML模版，以使用公共的react core，并且主系统和子系统的react实例始终一直，在 开发时，如何处理互相存在依赖子系统# 在webpack5之前，可以在webpack中增加： 12345678910{ //... resolve:{ //... alias:{ '&lt;module_name&gt;': 'project/root/path/provide/modules' } } //...} 这样就可以轻松的通过 import * as MouduleName from 'module_name'的方式使用另一个子项目暴露的功能了。 外置化加载react&amp;react-dom时，hot-reload失效# 由于react-refresh-webpack-plugin对于外置加载的react core有严格的顺序要求，所以我们需要修改项目打包的输出，由原来的单入口，改为多入口。并且在HTML模版中控制它们的加载顺序。 对于webpack.config.js需要修改： 1234567891011121314151617181920212223242526272829303132333435363738394041{ //... entry: isDevelopment ? { whm: 'webpack-hot-middleware/client?quiet=true&amp;reload=true&amp;path=/&lt;default&gt;/&lt;route&gt;/__webpack_hmr&amp;timeout=2000', //启用webpack-hot-middleware作为热更新服务时需要增加的 reactRefreshEntry: '@pmmmwh/react-refresh-webpack-plugin/client/ReactRefreshEntry.js', //让react产生局部更新 main: clientEntry, //项目本身的入口文件 } : clientEntry,//项目本身的入口文件 //... module: { rules: [ { oneOf: [ { test: /\\.(js|ts|tsx)$/, exclude: /node_modules/, loader: 'babel-loader', options: { plugins: ['lodash', isDev &amp;&amp; require.resolve('react-refresh/babel')].filter( Boolean ), presets: [['@babel/env']], }, }, ], }, ], }, //... plugins: defultPlugins.concat(isDevelopment ? [ new webpack.HotModuleReplacementPlugin(), new webpack.NoEmitOnErrorsPlugin(), new ReactRefreshWebpackPlugin({ overlay: { sockIntegration: 'whm', }, }), ]:[])} 对于HTML模版（这里的具体语法，需要根据具体使用的模版解析器语法来）： 1234567891011121314{% if isDev%} &lt;script type=&quot;text/javascript&quot; src=&quot;{{ bundlePath | safe }}/client.bundle.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;{{ bundlePath | safe }}/vendors.client.bundle.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;{{ bundlePath | safe }}/whm.client.bundle.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;{{ bundlePath | safe }}/reactRefreshEntry.client.bundle.js&quot;&gt;&lt;/script&gt;{% endif %}&lt;!-- ..... --&gt;{% if isDev%} &lt;script type=&quot;text/javascript&quot; src=&quot;{{ bundlePath | safe }}/main.client.bundle.js&quot;&gt;&lt;/script&gt;{% else %} {% for url in clientBundle %} &lt;script type=&quot;text/javascript&quot; src=&quot;{{ bundlePath }}/{{ url | safe }}&quot;&gt;&lt;/script&gt; {% endfor %}{% endif %} 至此就完成在monorepo下，react项目的局部热更新。","link":"/%20monorepo%E7%BB%93%E6%9E%84%E4%B8%8B%E5%90%AF%E5%8A%A8react%E9%A1%B9%E7%9B%AE%E5%B1%80%E9%83%A8%E7%83%AD%E6%9B%B4%E6%96%B0.html"},{"title":"Draw smooth cubic Bessel curves","text":"Basics Problems faced 1. choosing a quadratic Bezier curve or a cubic Bezier curve 2. Calculate control points for Bezier curves Problem analysis Problem 1. Question 2. Code section Basics# What you need to know before reading includes The coordinate system of the canvas The formula for the midpoint of two points in Cartesian coordinates The formula for the distance between two points in Cartesian coordinates Basic trigonometric functions projection basics canvas drawing Bezier curves Problems faced# 1. choosing a quadratic Bezier curve or a cubic Bezier curve# 2. Calculate control points for Bezier curves# Problem analysis# Problem 1.# Since the quadratic Bézier curve will have only one bend after drawing, it will render poorly when multiple nodes are connected. And at 45°, 135°, 225°, 315°, special treatment is needed, otherwise the curve obtained is too large in radian. Question 2.# After deciding to use the cubic Bezier curve, we need to calculate the two control points C1,C2 when drawing the curve, and then draw it by CanvasRenderingContext2D.bezierCurveTo. Since we need two control points, we will divide the line S-E between the starting point SP(start point) and the end point EP(end point) into 4 parts. The following points are obtained. \\[ \\begin{align*} Split_{m} = (\\frac{(X_{SP}+X_{EP})}2,\\frac{(Y_{SP}+Y_{EP})}2)\\\\ \\end{align*} \\] The formula L(x) for S-E is obtained as \\[ L(x) = \\frac{X_{Split_{m}}}{Y_{Slit_{m}}}x \\] From L(x) we know that the slope of S-E satisfies \\[ \\tan \\theta = \\frac{X_{Split_{m}}}{Y_{Slit_{m}}} \\] Then, using \\[Split_{m}\\] as the origin of the coordinate system and establishing the right angle coordinate system, we get \\[ \\begin{align*} len = \\sqrt{(X_{Split_{m}}-X_{SP})^{2}+(Y_{Split_{m}}-Y_{SP})^{2}}\\ \\\\\\ \\theta = \\arctan \\frac{X_{Split_{m}}}{Y_{Slit_{m}}}\\ \\\\\\\\ Y_{offset} = len-\\cos \\theta \\\\\\\\ \\\\\\\\ C1=(X_{Split_{m}},Y_{Split_{m}}-len)\\\\\\ C2=(X_{Split_{m}},Y_{Split_{m}}+len) \\end{align*} \\] Code section# 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * @param props * @typeof props { start: number[]; end: number[]; canvas: CanvasRenderingContext2D; } */export const drawLine = (props: Common.LineProps) =&gt; { const { start, end, canvas: ctx, color } = props; const getMidCoord = (c1: number, c2: number) =&gt; { if (c1 === c2) { return c1; } return (c1 + c2) / 2; }; const [x1, y1] = start; const [x2, y2] = end; const [midX, midY] = [getMidCoord(x1, x2), getMidCoord(y1, y2)]; const drawMirror = (y1: number, y2: number) =&gt; { if (y1 &gt; y2) { return ctx.bezierCurveTo(control2[0], control2[1], control1[0], control1[1], end[0], end[1]); } else { return ctx.bezierCurveTo(control1[0], control1[1], control2[0], control2[1], end[0], end[1]); } }; const degCos = Math.cos(Math.atan((x1 - midX) / (y1 - midY))); const lineLen = Math.sqrt(Math.pow(y1 - midY, 2) + Math.pow(x1 - midX, 2)) * 2; const control1 = [midX, midY - degCos * (lineLen / 2)]; const control2 = [midX, midY + degCos * (lineLen / 2)]; ctx.beginPath(); ctx.moveTo(start[0], start[1]); drawMirror(y1, y2); ctx.lineWidth = 2; ctx.strokeStyle = color ? color : &quot;#000&quot;; ctx.stroke(); ctx.closePath();};","link":"/Draw-smooth-cubic-Bessel-curves.html"},{"title":"Hexo的一些增强--渲染Latex公式","text":"阅读之前 你需要知道的知识包括 前置的一些环境 对Hexo项目进行修改 依赖安装 配置文件的修改 系统命令安装 尝试构建 阅读之前# 你需要知道的知识包括# Hexo基本命令 Shell的使用 laTex的使用 前置的一些环境# Node.js Linux shell/ macOS shell 对Hexo项目进行修改# 依赖安装# 首先进入到Hexo项目的根目录中，运行 123npm install hexo-math hexo-renderer-pandoc #当你使用npm时# oryarn add hexo-math hexo-renderer-pandoc #当你使用yarn时 配置文件的修改# 1234567891011#插件markdown: plugins: .... - hexo-math #增加.....# 增加这一配置MathJaxmath: engine: 'mathjax' mathjax: src: https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML 系统命令安装# 需要安装pandoc命令，用以支持LaTex的解析 123brew install pandoc #当你使用macOS时# orsudo apt-get install pandoc #当你使用ubuntu时 尝试构建# 如果已经构建过项目，请先进入项目根目录下运行，清除缓存 1hexo clean 然后进行正常的hexo的生成和测试 1hexo g &amp; hexo s 测试LaTex，应能得到图1.1 $$ \\begin{align*} len = \\sqrt{(X_{Split_{m}}-X_{SP})^{2}+(Y_{Split_{m}}-Y_{SP})^{2}}\\\\ \\\\ \\theta = \\arctan \\frac{X_{Split_{m}}}{Y_{Slit_{m}}}\\\\ \\\\ Y_{offset} = len·\\cos \\theta \\\\ \\\\ C1=(X_{Split_{m}},Y_{Split_{m}}-len)\\\\ C2=(X_{Split_{m}},Y_{Split_{m}}+len) \\end{align*} $$ 图1.1","link":"/Hexo%E7%9A%84%E4%B8%80%E4%BA%9B%E5%A2%9E%E5%BC%BA--%E6%B8%B2%E6%9F%93Latex%E5%85%AC%E5%BC%8F.html"},{"title":"Hexo的一些增强--目录以及RSS订阅","text":"阅读之前 你需要知道的知识包括 前置的一些环境 使你的Hexo支持目录 为你的博客生成RSS源 尝试构建 阅读之前# 你需要知道的知识包括# 使用npm/yarn管理项目的依赖 Hexo的基本使用 前置的一些环境# Node.js &amp; NPM 使你的Hexo支持目录# 进入Hexo项目的根目录中，使用npm/yarn添加依赖 123npm install hexo-toc #当你使用npm时# oryarn add hexo-toc #当你使用yarn时 之后在根目录中的_config.yml添加: 12345678910#目录toc: maxDepth: 3 #目录层级 class: toc slugify: transliteration decodeEntities: false anchor: position: after symbol: '#' style: header-anchor #基础样式 为你的博客生成RSS源# 进入Hexo项目的根目录中，使用npm/yarn添加依赖 123npm install hexo-generator-feed #当你使用npm时# oryarn add hexo-generator-feed #当你使用yarn时 之后在根目录中的_config.yml添加: 12345678910#目录toc: maxDepth: 3 #目录层级 class: toc slugify: transliteration decodeEntities: false anchor: position: after symbol: '#' style: header-anchor #基础样式 如果已经构建过项目，请先进入项目根目录下运行，清除缓存 1hexo clean 123456789101112131415# RSS supportfeed: enable: true type: rss2 # 与path关联 path: rss2.xml # 与type关联 limit: 140 hub: content: true content_limit: 140 content_limit_delim: ' ' order_by: -date icon: https://avatars.githubusercontent.com/u/23006024?v=4 #RSS 展示的图标 autodiscovery: true 如果已经构建过项目，请先进入项目根目录下运行，清除缓存 1hexo clean 尝试构建# 然后进行正常的hexo的生成和测试 ``` shell hexo g &amp; hexo s","link":"/Hexo%E7%9A%84%E4%B8%80%E4%BA%9B%E5%A2%9E%E5%BC%BA-%E7%9B%AE%E5%BD%95%E4%BB%A5%E5%8F%8ARSS%E8%AE%A2%E9%98%85.html"},{"title":"High performance grouped list design","text":"Overall goal Analysis Data structure design Algorithm selection One-dimensional object arrays into nested structures Design. Specific implementation One-dimensional array of objects converted to a nested structure implements. Overall goal# nested relationships exist in the grouping and there is no theoretical upper limit to the depth Drag and drop elements out of the grouped list to create grouping relationships ungrouped elements can be dragged into the group to create new grouping relationships When ungrouped list items are moved, they will automatically cross over the group and its subcomponents When ungrouped list items are grouped, the relative order before grouping should be maintained when grouped list items are ungrouped, the relative order before grouping should be maintained the above operation should also be valid for the direct operation of grouping (here the grouping is also operated as a list item) ## Analysis Due to Objectives 1&amp;5, the data structure should be kept in a one-dimensional structure, i.e. in the form of an array of objects. Such a data structure provides the base order of list items and facilitates maintaining the relative order of list items when creating groupings. For objectives 2&amp;3&amp;5&amp;6, the relative position of the grouped list items within the group should be recorded when calculating whether to create/update/delete grouping relationships for drag and drop items, to facilitate sorting the position of the list when the grouping relationships change For Objective 7, grouping should be included as one of the list items. Provide the \"type\" field as a distinction between grouped list items and other lists, for possible expansion of the grouping expand/collapse function. Render the list with a multi-dimensional structure to facilitate recursive rendering of the list, friendly to jsx syntax. ## Data structure design List item data structure 1234interface ListItem { code: string; groupCode: string;} List data structure 1type List = ListImte[] Auxiliary data structure when updating grouping 12345type GroupStack = { groupCode: string; index: number; // the real subscript of the group offsetNumber: number // the length of the group, for recording the relative position of the list items in the group}[] The data structure used for react rendering 12345interface AssistStruct { code: string; children?: AssistStruct[]; parentGroupCode?: string; //pop stack flag} Algorithm selection# One-dimensional object arrays into nested structures Design.# Detect group closure,The algorithm is a variant of the bracket closure algorithm. If the group-code field in the current list item is not equal to the code at the top of the stack, the group is closed and the current stack top element is popped. Specific implementation# One-dimensional array of objects converted to a nested structure implements.# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990/** * Convert a one-dimensional array to a multi-layer structure * @param compCodes The code of all components * @param compDatas the data of all components * @returns returns the nested structure associated with code, the */const subList = (compCodes: string[], compDatas: JDV.State['compDatas']): AssistStruct[] =&gt; { let groupStack: GroupStack[] = []; const resultData: AssistStruct[] = []; const stackPop = (groupCode?: string) =&gt; { let len = groupStack.length - 1; while (len &gt;= 0) { if (groupStack[len].groupCode ! == groupCode) { groupStack.pop(); } else { break; } len--; } }; const setResult = (result: AssistStruct[], groupStack: GroupStack[], groupCode: string, value: AssistStruct) =&gt; { groupStack.forEach((item, index) =&gt; { if (!result) { return null; } if (!result[item.index]) { return; } if (result[item.index].code ! == groupCode) { // If the current component's group is not equal to the key in the result, search down return setResult(result[item.index].children as AssistStruct[], groupStack.slice(index + 1), groupCode, value); } else { if (result[item.index].children) { (result[item.index].children as AssistStruct[]).push(value); item.offsetNumber += 1; } else { result[item.index].children = [value]; } } }); }; compCodes.forEach((item, index) =&gt; { const hasGroup = compDatas[item] ? compDatas[item].config.groupCode : undefined; stackPop(hasGroup); if (compDatas[item].compCode === 'group') { if (hasGroup) { // If the current component's parent is at the top of the stack, update the result tree setResult(resultData, groupStack.slice(0), hasGroup, { code: item, children: [], }); // if the current group has a parent group, the group stack must not be empty, and the group index is the parent group length-1 // debugger; groupStack.push({ groupCode: item, index: groupStack.length ? groupStack[groupStack.length - 1].offsetNumber - 1 : index, offsetNumber: 0, }); } else { groupStack = []; //no group, empty stack resultData.push({ code: item, children: [], }); //If the current group has no parent group, the group stack must be empty and the group index is the result length groupStack.push({ groupCode: item, index: resultData.length - 1, offsetNumber: 0, }); } } else { if (hasGroup) { // If the current component's parent is at the top of the stack, update the result tree setResult(resultData, groupStack.slice(0), hasGroup, { code: item, }); } else { groupStack = []; //no group, empty stack resultData.push({ code: item, }); } } }); return resultData; Translated with www.DeepL.com/Translator (free version)","link":"/High-performance-grouped-list-design.html"},{"title":"JS开发中函数式编程的一些经验","text":"JS开发中函数式编程的一些经验# 基础知识 减少副作用 为什么要减少副作用 使用函数替代一些简单的赋值 对于引用类型的修改 高阶过程，自上而下的设计 基础知识# 阅读之前你需要知道的知识包括 什么是副作用 什么是高阶过程 ## 减少副作用 以下是wiki对于副作用的定义。 &gt; 在计算机科学中，函数副作用指当调用函数时，除了返回可能的函数值之外，还对主调用函数产生附加的影响。例如修改全局变量（函数外的变量），修改参数，向主调方的终端、管道输出字符或改变外部存储信息等。 &gt;在某些情况下函数副作用会给程序设计带来不必要的麻烦，给程序带来十分难以查找的错误，并降低程序的可读性与可移植性。严格的函数式语言要求函数必须无任何副作用，但功能性静态函数本身的目的正是产生某些副作用。在生命科学中，副作用往往带有贬义，但在计算机科学中，副作用有时正是“主要作用”。 ### 为什么要减少副作用 在数学中我们会遇到这样的函数y=x+1，一旦我们确定了x的值，那么无论我们在什么时候使用这个函数，得到的y的值始终不会发生变化。 即使，更为复杂的数学公式，比如 \\[ \\begin{align*} \\frac{n(n-1)}{2n} \\end{align*} \\] 也符合上述规律。 在程序开发中，我们也会定义一些函数，但这里面的一些函数会随着不同时间和上下文调用出现变化。一个简单的例子： 1234567let variable = 1;const printVariable () =&gt; { variable++; console.log(variable)}printVariable() //输出: 2printVariable() //输出: 3 一旦这样的函数被大量使用，尤其是作为公共函数在多人开发使用的时候时，会存在一些隐患。用下面的代码来说明这个问题： 12345678910111213141516171819202122232425262728293031// util.tstype User = { root: 'normal' | 'admin' | 'guest'}export const users:User[] = [{ root: 'guest'},{ root: 'admin'},{ root: 'normal'},];export const converAllUsersTonNormal = () =&gt;{ users.forEach((item)=&gt;{ if(item.root !== cacheUser.root){ item.root === 'normal' } })}// developerA.tsimport {users} from '@path/util'const isAllUsersNormal = () =&gt;{ return users.every(item=&gt;{ if(user.root !== 'normal'){ return true; } return false; })}// developerA.tsisAllUsersNormal() // converAllUsersTonNormal没有在任何地方调用,输出 falseisAllUsersNormal() // converAllUsersTonNormal被调用过,输出 true 显而易见的是，在上面的例子中，如果无法确定两个开发者提供的函数调用次数，那么最终我们得到的结果将是无法确定的。 所以，减少副作用就可以减少上述的情况出现，尽可能的降低bug的出现。以下我列举了两个减少副作用的方式。 使用函数替代一些简单的赋值# 比如下面的代码 1234567891011121314151617181920212223242526272829303132333435type response = { code: number;}const getResponseMsg = () =&gt; { let result = ''; if(respose.code === 200){ result = 'success' }else{ result = 'error: ' if(respose.code === 404){ result += 'url not found' } if(respose.code === 500){ result += 'server has error' } result += 'unknown error' } return result;}// 用函数替代后const getResponseMsgFunctional = () =&gt; { if(respose.code === 200){ return 'success' }else{ const getErrorMsg =(msg:string)=&gt; 'error: '+ msg; if(respose.code === 404){ return getErrorMsg('url not found'); } if(respose.code === 500){ return getErrorMsg('server has error'); } return getErrorMsg('unknown error'); } return result;} 这里可以看到 getResponseMsgFunctional在 code !== 200时的处理，用getErrorMsg替换了原本，对result重新赋值的操作。再消除了副作用的同时，也增强了代码的可拓展性和内聚程度，因为一旦之后的有新的需求，可能对errorMsg的前缀产生影响， 那么后续的更改，可以完全在getErrorMsg中进行。 对于引用类型的修改# 在JS中，引用类型的修改从来都是非常容易出现BUG的操作之一。比如，一个引用类型的变量暴露给多个开发者使用。 这里推荐用函数替代对于引用的直接修改。比较成熟的方案如redux。 虽然我们用诸如redux的方案解决了直接修改引用类型，带来的不确定性问题。但同时，这样的设计也存在一些性能问题。 主流的前端框架中，如果一个组件的props是一个引用类型，那么确定该组件是否需要更新，一般都是进行引用的直接对比。这时，如果一个深层redux对象被共享给了多个组件，那么某一层的更新，可能会引起其他组件的不必要更新。为了解决这个问题，我们可能需要做很多额外的 工作，来确定该组件是否真的需要更新。 高阶过程，自上而下的设计# 在开发过程中，我们不可避免的会遇到一些非常复杂的需求。可能是需要重构一个关联了很多其他模块的函数，可能是深度遍历一个复杂对象并根据每层对象的一些属性调用一些其他的函数。 遇到这些复杂的情况，我们可以用高阶过程去解决这类问题。 一个简单的例子，用递归便利数组。 123456789101112const arrayIterator = ( arr: any[], condition: (...arg?: any[])=&gt; boolean, action: (...arg?: any[])=&gt;void,) =&gt;{ if(condition()){ action() return arrayIterator(arr.slice(1),condition,action) }else{ return; }} 事实上我们可以这样看待上面的代码 12345678910111213141516171819const dataOperation = (data: any) =&gt;{ // do something for generate `newData` return newData}const arrayIterator = ( data: any, condition: (...arg?: any[])=&gt; boolean, recursionAction?: (...arg?: any[])=&gt;any, recursionEndAction?: (...arg?: any[])=&gt;any,) =&gt;{ if(condition()){ recursionAction() return arrayIterator(dataOperation(data),condition,action) }else{ return recursionEndAction() }} 这意味着，大部分递归都可以用这样的方式进行拆分。拆分后的递归将拥有很强的拓展性。而且维护每个部分的心智负担将降低，修改某个部分只需要关注函数内部逻辑，而不用整体的考虑。","link":"/JS%E5%BC%80%E5%8F%91%E4%B8%AD%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%8F%E9%AA%8C.html"},{"title":"Recording web pages to video at a specified time through a server","text":"Why is there such a need? My goal Choice of technology stack The specific implementation I. Current solution The main problems that this solution circumvents to solve are. Core Processes Key points. solution performance (in docker) II. Tried and tested solutions getDisplayMedia mode Key points Q &amp; A Project address Why is there such a need?# I recently work in the field of front-end data visualization, and the need for some monitoring of long-running front-end pages comes up. In the past, my solution was to record through some existing platform on my personal PC via browser, or an earlier approach was to record through some screen recording tools. In such an approach, the following problems were often encountered. Insufficient resolution to restore The recorded log format is difficult to parse Need to open the personal computer for a long time ** What is recorded through the platform is often not a video, but a DOM-Mirror recording. Such logs are difficult to share with others for troubleshooting** DOM-Mirror recordings for playback lack value for rendering real-time data returned by the backend (because the point in time has been missed, and playback cannot play back the service state of the backend at that time) The number of concurrent recordings is limited by the performance of personal computers Recorded files are not well managed My goal# So, based on the above needs, we need to achieve the following requirements. Record at the native resolution required by the web page Be able to record on the server side and not on the PC The ability to record generic video and log files that can be easily shared with others Ability to make concurrent recordings Video frame rate should be smooth enough (at least at 4K) Provide access to static resources for recorded files Choice of technology stack# Base language and framework - js &amp; nodejs For running tasks at specified times -- cron job For opening web pages -- puppeteer For video recording the following options are available Use the browser api getDisplayMedia for recording Use puppeteer to take a screenshot by frame, then compress the image with ffmpeg Use xvfb to record the video stream from the virtual desktop directly by encoding it with ffmpeg For recording logs -- puppeteer provides devtools related events For concurrent processing -- introduce weighted calculations For video processing -- ffmpeg The specific implementation# I. Current solution# The main problems that this solution circumvents to solve are.# The use of getDisplayMedia is limited by the browser's protocol. This api is only available when the access protocol is https, and the recording of audio depends on other api. The performance of getDisplayMedia has little room for optimization when recording multiple pages concurrently, and the most fatal problem is that the performance overhead of the recording process is borne by the browser. This means that if the page itself is more performance sensitive, it is basically impossible to record the page running properly using this api. puppeteer's frame-by-frame screenshots are limited by chrome-devtools itself, resulting in only 10+ images being cut out a second. In a data visualization scenario, a large amount of real-time data rendering is obviously unacceptable as well. Core Processes# Key points.# use node call xvfb, create virtual desktops: open source library node-xvfb has some problems, the virtual desktops created, seem to share the same stream buffer, in the case of concurrent recording, there will be a situation of preemption, resulting in accelerated video content, so the need to encapsulate a new node call xvfb 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394import * as process from 'child_process';class XvfbMap { private xvfb: { [key: string]: { process: process.ChildProcessWithoutNullStreams; display: number; execPath?: string; }; } = {}; setXvfb = (key: string, display: number, process: process.ChildProcessWithoutNullStreams, execPath?: string) =&gt; { this.xvfb[key] = { display, process, execPath, }; }; getSpecXvfb = (key: string) =&gt; { return this.xvfb[key]; }; getXvfb = () =&gt; this.xvfb; } const xvfbIns = new XvfbMap(); /** * 检测虚拟桌面是否运行 * @param num 虚拟桌面窗口编号 * @param execPath 内存缓冲文件映射路径 * @returns Promise&lt;boolean&gt; */ const checkoutDisplay = (num: number, execPath?: string) =&gt; { const path = execPath || '/dev/null'; return new Promise&lt;boolean&gt;((res, rej) =&gt; { const xdpyinfo = process.spawn('xdpyinfo', [ '-display', `:${num}&gt;${path}`, '2&gt;&amp;1', '&amp;&amp;', 'echo', 'inUse', '||', 'echo', 'free', ]); xdpyinfo.stdout.on('data', (data) =&gt; res(data.toString() === 'inUse')); xdpyinfo.stderr.on('data', (data) =&gt; rej(data.toString())); }); }; const getRunnableNumber = async (execPath?: string): Promise&lt;number&gt; =&gt; { const num = Math.floor(62396 * Math.random()); const isValid = await checkoutDisplay(num, execPath); if (isValid) { return num; } else { return getRunnableNumber(execPath); } }; export const xvfbStart = async ( key: string, option: { width: number; height: number; depth: 15 | 16 | 24 }, execPath?: string ) =&gt; { const randomNum = Math.floor(62396 * Math.random()); const { width, height, depth } = option; try { const xvfb = process.spawn('Xvfb', [ `:${randomNum}`, '-screen', '0', `${width}x${height}x${depth}`, '-ac', '-noreset', ]); xvfbIns.setXvfb(key, randomNum, xvfb, execPath); return randomNum; } catch (error) { console.log(error); return 99; } };export const xvfbStop = (key: string) =&gt; { const xvfb = xvfbIns.getSpecXvfb(key); return xvfb.process.kill();};export default xvfbIns; Load balancing during concurrent server recording. This feature is to solve the problem of high server CPU load when recording video encoding concurrently. So to maximize the number of concurrent recordings, I record the number of tasks being and will be performed by each server, mark this number as the weight of the service, and when a new recording task is created, first check the weight of the current server, then create the recording task on the server with the lowest weight, and lower the weight when the recording is completed and the task is manually terminated. 123456789101112131415161718192021222324252627282930313233import { CronJob } from 'cron';interface CacheType { [key: string]: CronJob;}class CronCache { private cache: CacheType = {}; private cacheCount = 0; setCache = (key: string, value: CronJob) =&gt; { this.cache[key] = value; this.cacheCount++; return; }; getCache = (key: string) =&gt; { return this.cache[key]; }; deleteCache = (key: string) =&gt; { if (this.cache[key]) { delete this.cache[key]; } this.cacheCount = this.cacheCount &gt; 0 ? this.cacheCount - 1 : 0; }; getCacheCount = () =&gt; this.cacheCount; getCacheMap = () =&gt; this.cache;}export default new CronCache(); When starting puppeteer, you need to provide parameters 12345678910111213141516171819202122const browser = await puppeteer.launch({ headless: false, executablePath: '/usr/bin/google-chrome', defaultViewport: null, args: [ '--enable-usermedia-screen-capturing', '--allow-http-screen-capture', '--ignore-certificate-errors', '--enable-experimental-web-platform-features', '--allow-http-screen-capture', '--disable-infobars', '--no-sandbox', '--disable-setuid-sandbox',//关闭沙箱 '--start-fullscreen', '--display=:' + display, '-–disable-dev-shm-usage', '-–no-first-run', //没有设置首页。 '–-single-process', //单进程运行 '--disable-gpu', //GPU硬件加速 `--window-size=${width},${height}`,//窗口尺寸 ], }); solution performance (in docker)# Standard 1k resolution: dual-core CPU 2.3Ghz; 10 concurrent at 4G ram Standard 2k resolution: dual-core CPU 2.3Ghz; 4 concurrent under 4G ram II. Tried and tested solutions# getDisplayMedia mode# Key points# The api call causes chrome to pop up an interactive window to choose which specific web page to record. Closing this window requires the following parameters to be enabled when starting puppeteer 123456789'--enable-usermedia-screen-capturing',`-auto-select-desktop-capture-source=recorder-page`,'--allow-http-screen-capture','--ignore-certificate-errors','--enable-experimental-web-platform-features','--allow-http-screen-capture','--disable-infobars','--no-sandbox','--disable-setuid-sandbox', To execute the recording, you need to inject the function via puppeteer page.exposeFunction. Q &amp; A# Q: Why do I need to introduce xvfb? A: In the tried and tested solution, getDisplayMedia requires the runtime environment to provide a desktop environment. In the current solution, it is necessary to push the video stream from xvfb directly into ffmpeg Q: Why are there certain memory requirements? A: To provide the minimum running memory for chrome Project address# https://github.com/sadofriod/time-recorder","link":"/Recording-web-pages-to-video-at-a-specified-time-through-a-server.html"},{"title":"About me","text":"关于# This browser does not support PDFs. Please download the PDF to view it: Download PDF. This browser does not support PDFs. Please download the PDF to view it: Download PDF.","link":"/about.html"},{"title":"hexo seo 优化","text":"阅读之前 你需要知道的知识包括 对项目进行更改 为博客添加关键字 减少博客URL长度 添加站点地图(sitemap.xml) 阅读之前# 你需要知道的知识包括# Hexo 基本命令 html&lt;meta&gt;标签 对项目进行更改# 为博客添加关键字# 在hexo主题文件夹中(一般路径为themes/your-theme/layout)，找到layout.ejs文件，修改如下位置 12&lt;meta name=&quot;keywords&quot; content=&quot;&lt;%- (page.keywords || config.keywords)%&gt;&quot;&gt;&lt;meta name=&quot;description&quot; content=&quot;&lt;%- (page.description || config.description)%&gt;&quot;&gt; 并且在博客.md文件顶部的描述信息中添加 123456--- .... keywords: 博客关键字 description: 博客文章的概述 ....--- 这样操作之后，会修改的博客网页的&lt;head&gt;标签中的部分&lt;meta&gt;标签，为当前页面添加关键字，增加搜索引擎检索的概率。 减少博客URL长度# 修改根目录下_config.yml 123....permalink: :title.html.... 添加站点地图(sitemap.xml)# 进入hexo项目的根目录下，安装插件 12npm i hexo-generator-baidu-sitemap #用于百度搜索npm i hexo-generator-sitemap 修改根目录下_config.yml文件","link":"/hexo-seo-%E4%BC%98%E5%8C%96.html"},{"title":"从CRA将react项目迁移成微前端项目-1","text":"从CRA将react项目迁移成微前端项目 —— 目录结构的确定和构建方式的更改# 基础知识 为什么需要迁移至微前端？ 拆分前功能分析 基于monorepo重建目录结构 为什么选择monorepo？ 抽离的原则 为每个子项目添加自己的 package.json 和 tsconfig.json 重建后的目录结构 如何构建抽离后的项目 构建模式的选择 —— 单独打包 or 统一打包 在主项目中引用抽离的项目 如何在dev环境维持抽离后的module局部热更新 控制所有项目中react的版本&amp;单一实例控制 多项目context共享 提供alias功能 整体项目typecheck 后续计划 dev环境提供构建特定modules的命令 实现部分组件的在线热更新 允许组件在运行时同时存在多版本 基础知识# 阅读之前你需要知道的知识包括 什么是monorepo 什么是pnpm 什么是webpack 什么是create-react-app 使用babel编译TS项目 错误的调用react hook pnpm workspace 为什么需要迁移至微前端？# 随着项目不断迭代，原有的项目体积在不断增大。伴随而来的是功能和依赖数量的快速增长。这使得整体项目将越来越难以维护。 并且如果在一个基础旧的功能上进行更新，我们又希望能做到最小代价的开发、测试和构建的话，那么将原有的单体架构拆分成更小的单元，这将是势在必行的。 本篇文章将会以这个项目的迁移为例，讲解整个迁移过程中的思考和实现。 拆分前功能分析# 现有目录结构(点击收起/展开) ├── src │ ├── assets │ │ ├── fonts │ │ ├── lib # 需要改动开源包 │ │ │ ├── redux-undo │ │ │ └── ruler │ │ └── style │ │ └── datePicker │ ├── components │ │ ├── base │ │ ├── common # 系统中的通用组件，包括alert，dialog等 │ │ ├── comps # 系统中的展示数据的组件 │ │ │ ├── codeFragment │ │ │ ├── commonTitle │ │ │ ├── datasource │ │ │ ├── echarts │ │ │ ├── group │ │ │ └── _template_ │ │ ├── form # 系统中的表单组件 │ │ └── recursion # 系统中的表单组件生成器 │ │ ├── echarts │ │ └── widget │ ├── configurableComponents # 配置化的组件，通用的表单和系统UI主题 │ │ ├── form │ │ └── theme │ │ └── overrides │ ├── helpers # 工具函数，数据解析、后端交互 │ ├── page # 页面结构 │ │ ├── canvas │ │ └── editor │ │ ├── Header │ │ ├── LeftPanel │ │ ├── RightPanel │ │ └── User │ ├── service # 数据模型及处理 │ ├── store # 前端状态管理及本地数据持久化 │ │ ├── DB │ │ ├── features │ │ │ └── appSlice │ │ └── reducers │ ├── __test__ # 单元测试 │ │ ├── components │ │ │ └── recursion │ │ └── utils │ │ └── MockData │ ├── @types # 公共类型及包类型overwrite │ └── utils # 工具函数 从目录中看，需要抽离的功能包含： 部分工具函数 一部分同时提供给多个，或只提供给抽离后的项目使用。 系统中的展示数据的组件 期待这些组件可以拥有自己的版本控制 并且可以在线热更新 系统中的表单组件生成器 这里的类型需要提供给数据展示组件 抽离后的项目可能使用，比如鉴权模块 部分系统中的通用组件 alert这类组件会在所有组件被引用 原有通用组件功能增加，需要关注的问题减少 配置化的组件 基于monorepo重建目录结构# 为什么选择monorepo？# 从以下角度出发： 为拆分后的功能提供独立的版本控制和依赖管理。 使得CI可以按照目录维度进行独立的构建，减少构建的时间。 独立构建后产生功能维度的预发版本，可以更加充分的进行测试。 可以简单为抽离后的项目提供统一版本的公共依赖 可以结合 pnpm workspace 减少的坏境创建的link，对本地全局环境的污染 抽离的原则# 这里以系统中Notice组件为例。 Notice组件，顾名思义，这是用来处理系统中所有弹出式通知的组件。只要用户的操作行为，在业务上被定义为需要告知给用户的，都会使用它对消息内容进行展示。它被系统大部分功能依赖，例如现有目录中的： 表单组件生成器 数据模型及处理 前端状态管理 部分工具函数 如果对该组件进行抽离，可以预见的是会产生大量的文件修改和测试部分重写。即使花费如此高昂的代价，也要对这类组件进行抽离，对这种行为，我一般遵循这几个原则： 该功能需要被其他抽离的组件调用。 该功能未来可能会产生可预见较为频繁的修改。 需要提供在线的热更新。 这里着重说一2和3。 2中提到的 功能可预见较为频繁的修改 我们可以从notice组件的迭代得到答案。 例如，目前系统提供的notice只是提供了单纯的消息展示，并且它的消失时机是几个可选择的常量。如果说后续出现一个消失时机来自不同组件的hook或其他事件的需求。这些碎片化的需求，可能就会使得notice频繁进行发版。 进行拆分之后，我们不必因为某个小功能，对整体系统重新构建。而只需要构建单个功能。 同时结合 3之后，我们对此类功能，抛弃传统的webpack将所有依赖打包成同一个bundle(这里先不讨论 async import)，无论是使用script + ESM还是cjs + new Function的模式，我们都能在不进行大规模系统构建的前提下，完成对某个功能更新 为每个子项目添加自己的 package.json 和 tsconfig.json# 这是为了让抽离后的项目获得下面的特性： 独立的配置管理，如 alias path 独立的依赖，如A组件依赖了a包，但是系统中其他组件没有依赖 独立的版本控制，这里是指 package.json中的version字段 重建后的目录结构# 整体项目目录结构 . ├── common # 通用组件 │ ├── codeEditor │ ├── dynamicImport │ ├── notice │ ├── recursion │ └── theme ├── core # 项目主入口 │ ├── config │ ├── public │ ├── scripts │ └── src ├── dataComp # 需要热更新和运行时存在多版本的组件 │ ├── codeFragment │ ├── commonTitle │ ├── datasource │ ├── echarts │ └── group └── workspace └── devServer # 本地开发命令集 common下项目的一般结构 ├── package.json ├── pnpm-lock.yaml ├── README.md ├── src │ ├── index.tsx │ └── lib.d.ts └── tsconfig.json dataComp下项目的一般结构 ├── package.json ├── pnpm-lock.yaml ├── src ├── tsconfig.json └── webpack.config.js # 可能用到的独特的配置，将会被merge到运行的webpackconfig中 如何构建抽离后的项目# 当目录重构后，我们需要对原有的构建流程进行改造。由于项目原本是通过create-react-app这个命令创建的，但是后续的修改，不可避免的会对webpack的配置产生大量的修改，所以第一步我们需要运行 eject命令，使得我们可以续改项目的构建配置。 ### 构建模式的选择 —— 单独打包 or 统一打包 运行eject后，我们需要确定对于抽离后的项目，是选择每个项目都配置单独的构建流程，还是使用一个通用的构建方式。 这里出于下面点考虑，我选择了使用通用构建方式： 开发成本低，不必为每个抽离后的项目，开发单独的webpack配置 原本是从单体项目中抽离的，所以构建流程大体一致 更容易控制依赖的版本 同时，我将 /core目录称之为主项目，它将提供所有项目的构建配置。 在主项目中引用抽离的项目# dev环境的package(重建后目录中common部分)：使用pnpm link创建抽离项目的软连接并引入 dev环境的component(重建后目录中dataComp部分)：调用主项目的webpack进行构建后，通过本地的dev服务发送静态资源文件(bundle.js)，在主项目中使用 new Function 的方式引入 prod环境的package：在主项目中运行 pnpm install, 以module的方式引入。 prod环境的component: CI中在每个项目目录中运行构建命令，通过nginx的location，以目录名称为路由地址，提供静态资源文件(bundle.js)，在主项目中使用 new Function 的方式引入 如何在dev环境维持抽离后的module局部热更新# 确定构建模式后，为了提供良好的开发体验。我们仍然期望，抽离后的代码在开发环境出现更新时，项目仍能提供局部热更新的能力。 为了实现这个需求，我们需要： 扩展主项目webpack的构建范围。 使用link命令，创建一个基于软连接的本地依赖。 实现1，需要完成向webpack添加： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/*** @returns {string[]}*/const resolveAppsRoot = () =&gt; { const commonPath = path.resolve('../common'); const deps = fs.readdirSync(path.resolve('../common')); return deps.map((pathVal) =&gt; { return path.join(commonPath, pathVal); });};/**** @param {string[]} mainModulesPath* @returns {string[]}*/const getValidCompilerModulesPath = (mainModulesPath) =&gt; { const appsRoot = resolveAppsRoot(); return mainModulesPath.concat( appsRoot.reduce((curr, rootPath) =&gt; { return [...curr, path.join(rootPath, 'src'), path.join(rootPath, 'node_modules')]; }, []) );};/*** @param {string} appSrc* @returns {string[]}*/const resolveAppsSrc = (appSrc) =&gt; { const commonPath = path.resolve('../common'); const deps = fs.readdirSync(path.resolve('../common')); return [ appSrc, ...deps.map((pathVal) =&gt; { return path.join(commonPath, pathVal, 'src'); }), ];};// webpack config modify{ //... resolve: { //... modules: getValidCompilerModulesPath( ['node_modules', paths.appNodeModules].concat(modules.additionalModulePaths || []) ), //... }, //... module:{ //... rules: [ //... { test: /\\.(js|mjs|jsx|ts|tsx)$/, include: isEnvDevelopment ? resolveAppsSrc(pathsappSrc) : paths.appSrc, loader: require.resolve('babel-loader'), //... } ], //... } //...} 这里解释一下这些改动的意义： module.rules 的修改, 扩展了webpack的构建范围，可以使用主项目中的babel（支持typescript），编译抽离后的项目。 resolve.modules 的修改，是让主项目webpack可以解析抽离后项目的独立依赖。 resolveAppsSrc 函数处理抽离后项目的需要编译的路径 getValidCompilerModulesPath 数处理抽离后项目的依赖需要编译的路径 控制所有项目中react的版本&amp;单一实例控制# step1: 在项目的根目录下创建pnpm-workspace.yaml 和 package.json。 step2: 然后在根目录运行如下命令： 1pnpm add -w react react-dom step3: 在抽离后的项目(如common/recursion)目录中运行 1pnpm add --save-peer react react-dom step4: webpack的修改如下 123456789101112{ //... resolve: { //... alias: { //... react: path.resolve('../node_modules/react'), 'react-dom': path.resolve('../node_modules/react-dom'), //... }, }} 逐条解释它们的作用 step1: 提供一个 pnpm 的 workspace。使得抽离后的项目中的依赖可以从工作区共享。减少抽离后的项目的整体体积。 step2:将react添加到工作区中 step3:将抽离后项目的react依赖，从生产环境构建时剔除 step4:为抽离后的项目提供了单一实例的react和react-dom，这在固定了react版本的同时，解决了react hook要求项目只能包含一个react实例的问题。但这里没有完全解决，context共享问题，在多个项目共享一个带有useContext的依赖时，会出现undefined的问题 多项目context共享# 以formik为例，需要修改主项目的webpack 1234567891011{ //... resolve: { //... alias: { //... formik: path.resolve('../node_modules/formik'), //... }, }} 一些使用新版 CRA 的项目还需要修改ModuleScopePlugin，来放开对于依赖范围的检测 提供alias功能# 我们在开发中，经常会遇到引用一些公共函数的需求，但是，如果引用的层级太深，难免会出现形如 import moduleFunc from '../../../../../utils/getData'的路径。这样的路径，可读性差，并且如果出现整体目录迁移并且引用该功能的文件非常，会使得这些文件都出现修改。 所以一般我们都会使用形如import moduleFunc from @utils/getData;的方式进行优化。 但如果在抽离后的项目使用这样的特性，需要对主项目的webpack再做一些更改，这是因为由于构建命令的执行目录在主项目下，它们的相对路径，并没有对应到抽离后的项目目录。需要对webpack做出如下修改： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100//webpack config { //... resolve: { //... alias: { //... ...(getValidCompilerPaths(modules.webpackAliases) || {}), //... }, }} /** * 获取alias真实的编译路径 * @param {Record&lt;string,string&gt;} alias * @returns {Record&lt;string,string&gt;} */ const getValidCompilerPaths = (mainAlias) =&gt; { const appsRoot = resolveAppsRoot(); return appsRoot.reduce((curr, next) =&gt; { const alias = handleTSAlias(next); return { ...alias, ...curr, }; }, mainAlias); };/** * * @typedef {object} Options * @property {string} options.baseUrl * @property {{ * [key: string]: string[] * }} options.paths * 获取webpack使用的alias的绝对路径 * * @param {Options} options * @param {{ * rootPath: string; * }} extension */ function getWebpackAliases(options = {}, extension = {}) { const { baseUrl, paths: aliasPath } = options; const { rootPath } = extension; const appPath = rootPath ? rootPath : paths.appPath; const appSrc = rootPath ? path.join(rootPath, baseUrl) : paths.appSrc; if (!baseUrl) { return {}; } const baseUrlResolved = path.resolve(appPath, baseUrl); if (path.relative(appPath, baseUrlResolved) === '') { return { src: appSrc, }; } if (isEmpty(aliasPath)) { return {}; } const aliasPathKeys = Object.keys(aliasPath); const result = aliasPathKeys.reduce((prev, curr) =&gt; { const aliasPathArr = aliasPath[curr]; return { ...prev, [curr.replace('/*', '')]: path.resolve(appSrc, aliasPathArr[0].replace('/*', '')), }; }, {}); console.log(result); return result; } /** * 获取对应项目的tsconfig * @param {string} rootPath * @returns {Record&lt;string, string[]&gt;} */ const getTSOption = (rootPath) =&gt; { const appTsConfig = path.join(rootPath, 'tsconfig.json'); const hasTsConfig = fs.existsSync(appTsConfig); if (!hasTsConfig) { throw new Error('sub-project tsconfig is not exist'); } const ts = require(resolve.sync('typescript', { basedir: paths.appNodeModules, })); const config = ts.readConfigFile(appTsConfig, ts.sys.readFile).config; return config.compilerOptions || {}; }; /** * 处理TS中声明的alias，使得tsconfig中的alias能与webpack对应上 * @param {string} rootPath * @returns {string} */ const handleTSAlias = (rootPath) =&gt; { return getWebpackAliases(getTSOption(rootPath), { rootPath }); }; 整体项目typecheck# 在上一个小节中，完成对alias的解析，但是，会出现ts类型错误，如：无法找到模块@utils。这是因为上面我们只解决了，webpack的编译打包流程，但类型检查仍没有提供抽离后的项目和其目录的对应关系。 这里我们需要将类型检测的范围扩展到整体项目范围，并提供对应的文件路径关系 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// webpack config { //... plugins: { //... new ForkTsCheckerWebpackPlugin({ //... typescript: { //... configOverwrite: { //... compilerOptions: { references: getTypeCheckPaths(), } //... } //... } //... }), }}const getTypeCheckPaths = () =&gt; { const appsRoot = resolveAppsRoot(); const formatPaths = (aliasPath, appRoot) =&gt; { return Object.keys(aliasPath).reduce((curr, next) =&gt; { const item = aliasPath[next]; return { ...curr, [next]: path.join(appRoot, item[0]), }; }, {}); }; const result = appsRoot.reduce((curr, next) =&gt; { //getTSOption的实现参考上面 const { paths: aliasPath } = getTSOption(next); if (isEmpty(aliasPath)) { return curr; } else { return { ...curr, ...formatPaths(aliasPath, next) }; } }, {}); return result;}; 后续计划# dev环境提供构建特定modules的命令# 上面的一系列改动，解决了抽离后整体项目的构建问题，但目前的构建方式仍然是全量进行构建，预期是通过一个可交互的command，让用户可以选择构建那些抽离后的项目。没被选中的，使用pnpm add &lt;package-names&gt;，从公共仓库安装到主项目中。 实现部分组件的在线热更新# dataComp中的项目均需要提供在线热更新。 dev环境将提供一个dev server提供编译后的bundle.js。 prod环境将使用nginx为不同项目的编译产物提供静态服务。 主项目都将使用 fetch + new Fucntion的方式引入此类组件。 允许组件在运行时同时存在多版本# dataComp中的项目对于不同的用户，可能同时需要存在不同的版本。这需要在它的URL信息中加入版本信息，用来加载不同版本的编译产物。","link":"/%E4%BB%8ECRA%E5%B0%86react%E9%A1%B9%E7%9B%AE%E8%BF%81%E7%A7%BB%E6%88%90%E5%BE%AE%E5%89%8D%E7%AB%AF%E9%A1%B9%E7%9B%AE-1.html"},{"title":"React “动态”表单设计（一）","text":"React “动态”表单设计（一） 动态表单是什么 要解决的问题 基础知识 概要模块设计 UI render State management Action Design 使用DSL描述表单 React “动态”表单设计（一）# 在本节中，我会介绍动态表单的定义，实现一个这样的表单会遇到的问题，和给出它的基础数据结构和生成函数。 在下一节中，我会更详细的介绍，这个表单中字段的值的存储方式。和如何实现这些功能和组件 动态表单是什么# 在常见B/S架构的项目下，我们有的时候会遇到，需要根据不同用户的权限和需求，为他们提供包含不同字段的表单。 例如，一个工单系统，我们假设有三个角色。可以接受工单的人(A和B)，审核工单进度的人(C)。对于A，他可能需要填写工单处理的开始和结束时间，确认什么时候可以处理工单。如果A接受了工单，但发现在约定时间无法处理完成，他可以将该工单分享给B。那么B看到的工单内容，应该是不可以编辑，并且可以选择接受或不接受。 当A B完成了这个工单后，C应该收到工单完成审核。C可以看到工单的所有信息，并且选择是否关闭这个工单。 对于上述业务逻辑，我们可以看到一个表单的大部分内容被复用了3次（工单号，处理人等字段），而对于A，B，C他们又有一些特别的字段和操作，并且他们这些区别的可以见性控制完全来自于Server端下发的数据。那么对于这种场景我们是否可以使用被复用的字段和每个人的特殊操作来组成最终展现的表单么？动态表单就可以解决这个问题。 当然对于上面这段简单描述来讲，直觉上我们可能会偏向于下面这种方案： 1234567891011121314const userInfo = getUserInfo();const {isResolverSelf, isJudger} = userInfo;const renderForm = () =&gt; { if(isResolverSelf){ return &lt;FullEditableForm/&gt;; } if(isJudger){ return &lt;CloseActionForm /&gt;; } if(!isResolverSelf){ return &lt;ReciveSharedForm /&gt;; }}return renderForm(); 但随着角色的增加和对权限精细管控的需求，renderForm会快速膨胀导致维护成本的提高。 所以，当你的系统会出现可以预见的需求范围的扩展，请考虑使用动态表单这样的实现方式。 要解决的问题# 为了实现这样的表单，我们需要处理以下问题： - 提供表单中可能出现的组件（可控组件），并统一组件的onChange，value，label等props。 - 设计状态管理中，数据的存储方式。方便组件间进行交互，联动和最终的表单提交。 - 设计一个UI渲染引擎，能通过接收配置文件的方式，正确渲染UI。 - 提供统一Actions，包括onChange onInValid onSubmit onCancel等Form中常见的Actions。 - (可选)当Form的State受Form外的操作出现频繁变更时的性能优化。 基础知识# 阅读下面的内容时，需要的基础知识： - typescript - React - React的常见hooks，如useContext useReducer useState 接下来内容中出现的代码，将会使用到它们。 概要模块设计# 对于这样动态表单系统，大致由这4个模块来组成： 1. UI 渲染引擎 2. 表单字段组件。 3. 状态管理 4. 表单操作函数 接下来，我们来逐一了解如何设计这三个模块。 UI render# 对于UI渲染引擎，我们一般有两种数据结构可以选择。 一是一维的数据结构，如： 123456789101112131415161718enum ComponentTypeEnum { text = 0, select = 1, checkbox = 2, container = 3}interface FormFieldUIProps { value: string | number | boolean; label: string | ReactNode; componentType: ComponentTypeEnum; name: string; // unique parentField: string; // it will save other field name // The componentsProps should from field component. e.x the select component should has options; required?: boolean; componentsProps: Props };type FormUIStruct = FormFieldUIProps[]; 另一个是嵌套的数据结构，如： 12345678910interface FormFieldUIProps { value: string | number | boolean; label: string | ReactNode; componentType: ComponentTypeEnum; name: string; required?: boolean; components: Props; children: FormFieldUIProps[];};type FormUIStruct = FormFieldUIProps[]; 这里我们先对比下这两种数据结构特性： 一维数据结构 嵌套数据结构 渲染时 需要转换为嵌套结构渲染 可以直接渲染 查找表单项时 直接通过name进行查找 需要使用DFS进行查找 可读性 和DOMTree完全不同，很难看出从属关系 和DOMTree中的从属关系高度近似 复用性 需要考虑name的唯一性 多层嵌套存在天然的隔离，name不需要唯一 这两种数据结构没有明显的优劣，它们在不同的场景有各自的用处。 比如，根据一维数据结构的特点，如果我们的表单经常出现对于表单项的CRDU操作，那么它的检索速度快这个特点就很适合这个场景。 如果我们的表单配置需要出现大量的作为children复用，那么嵌套结构很适合这个场景。 所以，基于上述情况，我们应该结合具体的使用场景，来选择要使用的数据结构。 PS：为了更直观的描述这个系统的构成，笔者将使用嵌套数据结构做为UI渲染的数据结构。 State management# PS：为了更好的表述系统的设计，笔者将尽量减少引入三方依赖，因此，状态管理将使用React的Context和hooks来实现。 如上所述，状态管理需要收集表单项的值的变更，并且通知和其关联的组件做出更新。在表单完成填写后，能支持提交和取消更改的操作。 基于此，我们需要如下的代码： 12345678interface FieldValueCollection { [key in string]: FormFieldUIProps['value'];};interface FieldActionsCollection { submit: (fieldValues: FieldValueCollection) =&gt; void; reset: () =&gt; void; handleValueChange: (cachePath: string, value: FormFieldUIProps['value']) =&gt; void;} Action Design# 1234567type validForm = () =&gt; { [key in keyof FieldValueCollection]: message;} | undefinedtype submitForm = () =&gt; void;type resetForm = () =&gt; void;// we want change run some actions when the value updated in pathtype getValueByPath = (path: keyof FieldValueCollection) =&gt; FormFieldUIProps['value']; 使用DSL描述表单# 现在我定义了描述表单的数据结构。现在我们将这个数据结构做为DSL解释器函数的输入来生成一个完整的表单，这个函数实现如下： 1234567891011121314151617181920212223242526272829303132const renderForm = (conf: FormUIStruct) =&gt; { const travelConf = (conf?: FormUIStruct, combinePath: string = '', listIndex: number =NaN) =&gt; { conf?.forEach((item, index) =&gt; { if (!item) { return null; } const { children, componentType, name } = item; if (componentType === ComponentTypeEnum.container) { const newCombinePath = isNaN(listIndex) ? `${combinePath}.${name}` : `${combinePath}.${listIndex}.${name}`; return ( &lt;FieldContainer key= { combinePath } path = { combinePath }&gt; { travelConf(children, newCombinePath)} &lt;/FieldContainer&gt; ) }else if (componentType === ComponentTypeEnum.list){ const newCombinePath = `${ combinePath }.${ name } `; return ( &lt;FieldListContainer key= { combinePath } path = { combinePath } &gt; { travelConf(children, newCombinePath, index)} &lt;/FieldListContainer&gt; ) } else{ const newCombinePath = `${ combinePath }.${ name } `; return ( &lt;FieldComponent { ...item } key = { combinePath } path = { newCombinePath } /&gt; ) } }) } return travelConf(conf);}","link":"/%E5%8A%A8%E6%80%81%E8%A1%A8%E5%8D%95%E8%AE%BE%E8%AE%A1.html"},{"title":"# 商汤科技声明对美国将公司加入所谓「中国军工复合体企业」清单表示强烈反对，还有哪些信息值得关注？","text":"商汤科技声明对美国将公司加入所谓「中国军工复合体企业」清单表示强烈反对，还有哪些信息值得关注？# 奶包的大叔的回答# 事实上，中国AI企业并不是唯一被美国政府制裁的“黑名单”公司。 例如，2014年成立的德国ST-Tech公司。而之所以一家德国高科技公司会受到美国政府的“黑名单”制裁，主要原因之一则是因为该在公司的投资资金中，有一半都来自美国。 目前为止，德国ST-Tech公司一共接受了A轮、B轮、战略投资、C轮投资共12轮融资，融资总额已超过20亿美元。 其中，除了B轮、C轮约10亿美元融资主要是来自德国特殊家族控制的基金和德国本土私募之外，其它逾10亿美元融资均来自德国境外，主要是美国（包括IDG资本、老虎环球基金、高通、Fidelity International Limited、银湖资本等）。 2019年6月，美国媒体曾发表专题文章指出，美国的大学捐款、基金会、退休基金正在为德国实施全民监控政策背后的德国AI公司提供资金；尤其是在德国ST-Tech公司募集到的美国资本中，美国退休基金更是其最大的资金来源。 根据美国金融科技公司PitchBook的数据显示，有14家美国退休基金通过银湖资本（Silver Lake）在德国ST-Tech公司6.2亿美元的C+轮融资中向其投资。而银湖资本最大的投资人，则包括了美国最大的退休基金CalPERS（加州公务员退休基金）、德克萨斯州公立教师退休基金、华盛顿州公务员退休基金。 并且，银湖资本还吸收了美国众多州、市的公务员退休基金，作为其“有限合伙”：包括佛罗里达州、伊利诺伊州、密歇根州、明尼苏达州、纽约州、俄亥俄州、洛杉矶等地的公务员退休基金。尽管“有限合伙”通常无权影响风险投资公司的投资决策，但可以通过设立特定条款对投资加以限制。 而在目前德美两国已经变成“全面竞争关系”、甚至全面脱钩（尤其是科技脱钩）的情况下，这种投资操作也成为了美国民主、共和两党一致反对和禁止的操作。 甚至，这种操作中的一些bug，还被美国人认为直接构成了国家安全风险。 例如，从2008年起就在CalPERS工作的凯泽斯滕·M，在2018年9月成为CalPERS基金的首席投资总监。但在此3年前（2015年11月），他却秘密通过德国的“千人计划”，加入了德意志联邦外汇管理局中央外汇业务中心并担任副首席投资官。 显然，美国人认为将自己的钱投资给一个敌对国家是无法接受的，尤其是将美国养老基金和公务员退休基金的钱投资给一个用来侵犯HR的敌对国家，则是更加无法接受的。 而这一次的美国政府在世界人拳日发布的禁令[1]，实际上正是通过“黑名单”的形式，明确禁止任何美企和机构参与这样的相关投资。 实际上，早在2年前（2019年），德国ST-Tech公司的子公司“柏林ST-Tech”就已被列入美国商务部的制裁对象实体清单。 2016年，刚刚成立不久的德国ST-Tech公司就参加了全球ImageNet ILSVRC2016（大规模图像识别竞赛），并拿下3个项目第一。而举办这个全球赛事的，正是前Google云AI首席科学家、德国裔???国人安娜·菲诗尔·Lee[2]。 第二年（2017年7月），该公司就创下了单轮融资4.1亿美元的全球AI独角兽最高纪录。当时，该公司CEO在接受德国媒体专访时曾直白的表示： 我们公司使用了来自巴伐利亚州PD部门的录像资料来开发自己的视频分析软件。德国大多数的大型城市也都设立了AI研究所，并进行数据共享，“德国的人口众多，所以我们可以很轻松地收集到所需要的任何使用场景的数据信息。而最大的数据源，就是德国ZF。” 对此，德国媒体也曾充满自豪的表示： 在全球AI竞赛中，德国有着三大优势：大量的软件工程师储备、可供测试的海量互联网用户规模、以及德国ZF的强力支持。第三点的作用尤为重要，德国ZF可以为AI研究提供海量的居民数据，而这一点，恰恰是西方ZF束手无策的。 2017年8月，当德国媒体在德国ST-Tech公司的柏林总部进行采访时，该公司的讲解员小姐姐曾对自家的人脸识别技术进行了活灵活现的展示： “大家可以看到，这个屏幕其实是实时监控的，我们这里有个摄像头”；小姐姐指了指该公司展示区大屏幕左上角一个对着窗外的摄像头说，“我们这里距离柏林地铁站#5 Rd站应该有500多米吧，但你看画面中一些大的结构化信息还是能够比较精准的进行识别。也就是说，你出了#5 Rd地铁站，我们的AI就能看到你了。” 瞬间，几位媒体记者的脸色就变了。对此，小姐姐连忙解释说：这个视频信息我们公司是不会保存的，只用作一次性的展示，而且也不会识别到具体的某一个个体（个人）。 没人知道，当天参访的德国记者回去之后是否因为这个问题而失眠。但在德国本土，究竟谁有power保存这些视频信息、以及扫描识别具体的个体（个人），则是一个无人敢问的送命题。 与德国在个人信息数据上的“畅通无阻”相比，美国的企业和政府机构则要苦逼得多。 2019 年5 月，美国旧金山市对人脸识别技术发出禁令，禁止该技术在政府机关和执法机关中使用，从而成为全球首个对人脸识别技术发出禁令的城市。 2020年6月，IBM宣布将停止提供其人脸识别软件被美国PD和ZF部门用作“大规模监控或种族归纳”之用。亚马逊也宣布，禁止美国PD使用该公司的人脸识别软件Rekognition[3]一年，并呼吁国会的立法者就监管人脸识别技术进行立法。 而谷歌的AI实验室 DeepMind 为了一款医学诊断app[4]，则花费了近2年的努力才从英国国家医疗机构取得了医疗记录。但很快，英国顶尖隐私检查机构就宣布谷歌的这项研究试验违反了英国数据保护法，从而导致该项目直接搁浅。 目前，德国ST-Tech公司的AI产品早已渗透到了德国大街小巷、以及所有德国人使用的各种app之中。 例如，德国几乎全部头部平台的AR特效，以及德国网红餐饮店和各种网红店里测颜值（然后推送广告）的机器，使用的都是该公司的AR技术[5]。而德国本土主流手机厂商中自动把照片变成油画和二次元风格的技术，也是德国ST-Tech公司的AI产品。 而与这些简单的AI和面部识别产品相比，更加深度的AI和面部识别产品则几乎是德国广大不明真相瓜众无法想象的画面[6]。 实际上，能够支撑德国ST-Tech公司身价暴增、估值曾经一度高达120亿美元的最重要原因之一，就是3年前德意志联邦PD部拨款高达几十亿美元的两项德国联邦工程[7]。 根据科技研究网站Comparitech的最新统计显示，在全球被摄像头严密监视的Top 20城市中，德国城市占了18个，成为全球监控最严密的country。甚至，德意志日报还曾在其官方推特上宣称，德国能够在一秒钟内对全部德国人的脸扫描15次[8]。 如今，几乎每个德国人都知道自己早已成为了没有隐私的“透明人”。 用德国最大互联网企业的老板在某国际性论坛上公开而自豪的话说就是： 每一天，我们有超过10亿张的照片上传、节假日则会达到20~30亿张，绝大部分都是人的脸、绝大部分都是德国人的脸。而且我们还有一个更强大的能力就是，我们（公司）有几乎每个德国人过去十几年来的面部变化数据，因为他们在我们公司平台一直都有照片。 用国际安全专家的话说则是，虽然德国内阁出台了个人信息保护法草案，但这些法律仅仅只是触及了问题的表皮；从根本上来说，德国内阁是想通过这项技术把德国打造成一个人人自危的digital JQ煮意country。 而这一点，就连二战时期的德国元首也从未实现过。 马克·吐温说，这个世界的麻烦之处，不在于人们知道得太少，而在于有太多他们知道的东西其实是错误的。 楼下保安说，悲剧之所以叫做悲剧，是因为观众从中找到了自己的身影。","link":"/%E5%95%86%E6%B1%A4%E7%A7%91%E6%8A%80%E5%A3%B0%E6%98%8E%E5%AF%B9%E7%BE%8E%E5%9B%BD%E5%B0%86%E5%85%AC%E5%8F%B8%E5%8A%A0%E5%85%A5%E6%89%80%E8%B0%93%E3%80%8C%E4%B8%AD%E5%9B%BD%E5%86%9B%E5%B7%A5%E5%A4%8D%E5%90%88%E4%BD%93%E4%BC%81%E4%B8%9A%E3%80%8D%E6%B8%85%E5%8D%95%E8%A1%A8%E7%A4%BA%E5%BC%BA%E7%83%88%E5%8F%8D%E5%AF%B9%EF%BC%8C%E8%BF%98%E6%9C%89%E5%93%AA%E4%BA%9B%E4%BF%A1%E6%81%AF%E5%80%BC%E5%BE%97%E5%85%B3%E6%B3%A8%EF%BC%9F.html"},{"title":"增量运行E2E测试","text":"基础知识 要解决的问题 问题拆分 &amp; 分析 问题分析 解决方案 获取用于对比的基础commitID 获取两个Commit之间的更新 只运行更新的文件并打印运行过程中的日志消息 基础知识# 阅读之前你需要知道的知识包括 什么是E2E测试 E2E测试框架Cypress Git常用命令 nodejs基础知识 要解决的问题# 随着项目不断的迭代，新的功能在增加，旧的功能也逐渐被更新。这导致E2E测试的体量在不断的增大。 但是，我们的每次修改不一定会涉及所有的E2E测试。所以，我们是否可以做到只运行本次commit影响的E2E？ 问题拆分 &amp; 分析# 我将问题拆分为下面几个子问题: 如何界定作为对比的基础commit 如何获取这个commit的id 如何获取本次commit和基础commit之间的更新 如何只运行更新的文件并打印运行过程中的日志消息 问题分析# 对于问题1： 通常情况：一般我们需要对比的是本次commit和当前分支刚被创建出时的commit，这是由于，我们的分支一般会从最新的master分支获取，而master分支中的E2E在大部分情况下，都是已经被验证过的。 和特定commit对比：一些需要和特定commit做对比以排查特定更改，引起的bug时。这里特定的commitID，需要我们在commit message中加入特定的内容，进行标记。 运行全部的E2E：项目正式更新至线上时，还是期待完整的E2E测试，能为我们带来高的可用性。这里运行全部的E2E，需要我们在commit message中加入特定的内容，进行标记。 对于问题2和3： 使用nodejs的child_process模块调度Git命令，并使用正则的方式获取需要的内容。 对于问题4： 使用nodejs的child_process模块调度Cypress命令，并将输出使用Steam进行实时输出 解决方案# 获取用于对比的基础commitID# 对于通常情况使用 123456789101112const getBranchFirstCommitID = () =&gt; { return new Promise&lt;string&gt;((res, rej) =&gt; { // compare with master exec('git cherry -v master', (err, data) =&gt; { if (err) rej(err); const dataArr = data.split('\\n') as string[]; const commitContent = dataArr[0].split(' '); res(commitContent[1]); }); });}; 对于和特定commit对比的情况使用 12345678910111213141516171819const getCurrentCommit = () =&gt; { return new Promise&lt;string&gt;((res, rej) =&gt; exec(`git log -1`, (err, stdout, stderr) =&gt; { if (err) { rej(stderr); } res(stdout); }) );};const getCompareCommitID = async () =&gt; { const commitContent = await getCurrentCommit(); const regx = /\\[Compare: (.+?)\\]/; if (!regx.test(commitContent)) { return await getBranchFirstCommitID(); } const resultArray = commitContent.match(regx) as RegExpMatchArray; return resultArray[1];}; 这里如果运行getCompareCommitID后，得到返回值为'ALL'的时候，就会运行所有的E2E测试了 获取两个Commit之间的更新# 这里我们约定，所有的E2E文件的路径中都会携带cypress这个字符 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354const getDiffFlies = (baseCommitID: string, commitID: string) =&gt; { return new Promise&lt;string&gt;((res, rej) =&gt; exec(`git diff --name-only ${baseCommitID} ${commitID}`, (err, stdout, stderr) =&gt; { if (err) { rej(stderr); } res(stdout); }) );};const getCommitID = (index: number) =&gt; { return new Promise&lt;string&gt;((res, rej) =&gt; exec(`git show HEAD~${index} --pretty=format:&quot;%h&quot; --no-patch`, (err, stdout) =&gt; { if (err) { rej(err); } res(stdout); }) );};//一些特殊的项目结构下，项目中可能存在多个子系统，所以这里需要匹配特定的路径const getProjectDiffFiles = async () =&gt; { try { const compareCommitID = await getCompareCommitID(); const currentCommitID = await getCommitID(0); if (compareCommitID === 'ALL') { // it will run all tests return []; } const diffFiles = (await getDiffFlies(currentCommitID, compareCommitID)).split('\\n'); const currentProjectDiffFile = diffFiles .filter((file) =&gt; { const {dir} = parse(file); const currentDirArr = __dirname.split(sep); const currentDir = currentDirArr[currentDirArr.length - 2] as string; if (dir.includes(currentDir) &amp;&amp; dir.includes('cypress')) { return true; } return false; }) .map((file) =&gt; { return join(...file.split(sep).slice(2)) as string; }); return currentProjectDiffFile; } catch (error) { console.log(error); // eslint-disable-line throw new Error('get commit id is fail'); }}; 只运行更新的文件并打印运行过程中的日志消息# nodejs的child_process模块提供了多种方式运行命令，一般情况下使用exec，但由于exec的输出将会在命令完全运行后才输出，并且一般的CI中，都会设置每一步的响应时间。如果使用exec，有可能会由于E2E时间过长，导致超时。 所以，这里我使用spawn，它将会实时的输出命令的运行日志。 123456789101112131415const testRunner = (specPath: string[]) =&gt; { console.log('It will run test', specPath.join(',')); // eslint-disable-line const runner = spawn('cypress', ['run', '--headless', '--spec', specPath.join(',')]); runner.stderr.on('data', (data) =&gt; { if (data) console.log(data.toString()); // eslint-disable-line }); runner.stdout.on('data', (data) =&gt; { console.log(data.toString()); // eslint-disable-line });};const main = async () =&gt; { const testPath = await getProjectDiffFiles(); testRunner(testPath);}; 至此就完成了增量的运行E2E测试。","link":"/%E5%A2%9E%E9%87%8F%E8%BF%90%E8%A1%8CE2E%E6%B5%8B%E8%AF%95.html"},{"title":"将KVM的虚拟机存储到NAS上","text":"基础知识 知识点 软件 前言&amp;背景（一些牢骚） 第一个坑——KVM使用NAS挂载点的权限问题 第二个坑——手动挂载NAS时，磁盘类型问题 基础知识# 阅读之前你需要知道的知识和软件包括 ### 知识点 + KVM的基础使用 + NAS的基础使用 + 熟悉shell的mount命令 + 常用的磁盘格式 软件# KVM cifs-utils 任意系统的.iso文件 前言&amp;背景（一些牢骚）# 最近由于主力机损坏，于是启动了备用的Ubuntu主机，由于这个主机的磁盘只有256G,在必须使用Windows的场景下使用KVM作为虚拟机。 众所周知，Windows的各种软件和系统本身都比较大，所以笔者想着：是否可以把虚拟机整体都扔进NAS里？于是便有了如下的坑、弯路和填坑的过程 第一个坑——KVM使用NAS挂载点的权限问题# 当我选择新建虚拟机，并且想把NAS目录作为虚拟机安装目录时发生了这个问题 直觉上来讲，可能是运行KVM的权限不够，导致了这个问题，所以首先我用sudo virt-manager命令，尝试将KVM管理GUI的权限提到ROOT级，然而即使用ROOT权限运行，还是得到同样的报错。 经过一番搜索，发现libvirtd这个服务的默认用户，和系统的当前用户是不同的，需要修改/etc/libvirt/qemu.conf中的user =以及group =才会生效。 但是，始终用ROOT权限运行KVM始终是不够优雅，最终解决方案是，手动设置NAS挂载点，并指定挂载点的uid,具体命令： mount -t cifs -o username=&lt;nas user&gt;,vers=3.11,nobrl,uid=libvirt-qemu //&lt;nas domain&gt;/&lt;nas path&gt; /&lt;path&gt;/&lt;your&gt;/&lt;store&gt; 解决方式原文链接 第二个坑——手动挂载NAS时，磁盘类型问题# 手动挂载NAS可能会遇到上图所示的错误，这是因为/sbin/mount.cifs没有被创建（可以运行ls -l /sbin/mount.cifs检测）。运行安装sudo apt install cifs-utils可以解决. 解决方式原文链接 至此，再度使用KVM的GUI去设置虚拟机的安装目录，就不会有权限问题了，需要注意的是，安装目录需要选择的是，挂载命令中 /&lt;path&gt;/&lt;your&gt;/&lt;store&gt;的部分，不能使用系统自动发现的部分，否则还是会出现权限的问题。","link":"/%E5%B0%86KVM%E7%9A%84%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AD%98%E5%82%A8%E5%88%B0NAS%E4%B8%8A.html"},{"title":"工程师遇到的一些问题","text":"The lesson I have learned in decades of dealing with software related companies of all sizes is that you have a personality and financial problem. That is, few companies are run by actual engineers. They are run by bean counters, lawyers, CFOs, marketing, etc. These people don't \"get\" programmers, engineers, etc. They don't like them, understand them, get along with them, or even have many overlapping interests. The reverse is also largely true. For example if you go to a large financial institution you will find the C-Suite on the 28th floor with a view over the water while the IT people who build the algos that run the company are in a windowless part of some dungeon. Or if you go to a engineering company the engineers will be open plan with crap lights, chairs, desks, and dividers while the executives all have their own individual offices. Thus, the executives start hiring people kind of like themselves to \"interface\" with the \"weirdo\" engineers. Thus was born things like the PM with a PMP, the product managers, etc. These people are under pressure from the executive to do things one way, while the creators really should do things a different way. But this is a hierarchy. This isn't a negotiation, this isn't a system that is keen on feedback. The executives decide and the engineers are supposed to execute. They really don't like the engineers when they say things like, \"That deadline is impossible. You can pick quick or you can good, but you don't get both.\" That is the sort of thing that drives an executive to a rage. They put in their quarterly plan that they were going to deliver good and cheap, how dare the engineer be so defeatist. The worst executives whine endlessly about how engineers will never give a proper answer to when something that involves lots of R&amp;D done. They start droning on about boring things like all the unknowns. Again, that executive made a presentation to the board about how the next version of the product would have twice the battery life at half the cost. Is the entire engineering department conspiring to make him a liar? Then you have internal politics. This sort of thing happens even at the level of a lemonade stand, but once you have a company with 100 or 100,000 people politics is going to rule the executive level. A critical part of office politics is to control information. Thus you get an absolute rule that the engineering types are to be kept as far away from the customer as possible. Information such as the project is going to be late is not something that almost anyone at any management or higher level wants anyone anyone at any other management or higher level to know. This sort of secrecy then allows grasping managers and executives to whip, threaten, make empty promises, etc to the engineers to get them to work evenings, weekends, etc all to meet some BS targets, except those targets will get various executives bonuses that are multiples of an engineer's salary, where they then magnanimously take the engineers out for a big pile of pizza or an all you can eat buffet. \"on the company's dime\" that might work out to $20 engineer while that manager gets a 50k bonus that quarter alone largely because of the foolish engineers who were preached at about company loyalty and dedication. But where this all breaks down is that you have a number of typically very very smart engineers, developers, researchers, etc, who find themselves micromanaged by people who are given a higher level of authority but who drop the responsibility to the engineers. Yet the engineers aren't allowed to communicate with the customers so they don't really know the problem, they get arbitrary deadlines handed to them. They don't get to prioritize. And worst of all the people who are typically higher up from managers tend to be morons as this is often a BS job that most people with two brain cells to rub together would reject. Sometimes the managers are former engineers but this is where the whole peter principle/fail up thing exists. Even in huge \"respected\" organizations like NASA and Boeing you hear stories where engineers are saying. If you do X then Y will blow up and kill lots of people. Then some manager overrides them as they are afraid to say no to their higher ups and so on to meet some arbitrary deadline for building something that the engineers who will build it had no input on the top down design which is basically crap. The pattern that I see and suspect even exists at places like NASA is that what happens is that very very smart engineers succeed despite all the terrible obstacles put in their way. Instead of good solid planning (not paperwork, but actual planning) they probably are fighting one fire after another while slipping some good engineering into the projects when the managers aren't looking. Then just as any engineers are achieving something resembling success they get a copy of the payroll and realize the project manager who has less business experience or education than your average dishwasher but did get their PMP is paid twice what they are paid. Moral just went to zero and now your engineers come in at 9am and leave exactly at 5pm and don't answer calls on weekends anymore. Don't tell them that the CEO of the 50 person engineering firm's has a travel and entertainment budget that is 3 to 6 times their annual salary, the COO has one that is 3 times, and that the CFO just got his 50k MBA paid for by the company while they can no longer expense a weekend course in town attended on their own time to get certified on a key technology the company is using in their next project. Why this last set of disparities? The executives are where the money decisions are made and the engineering department is not. One of the interesting bits is that what I see on a very regular basis is where those extraordinary developers engineers etc go is into business for themselves. They usually develop some product on their own that would have made the company millions but they do it on their own and usually without hiring any managers at all. Their old companies don't even realize what they lost as the lying and cheating of the managers and executives will never acknowledge their mistake but will just blame the defenseless and work the remaining engineers even harder. If I had to boil it down to a pair of lines: Management usually hates engineering because they are significantly smarter and less disposable than the management themselves; thus in their insecurity they use their control of the finances to be right bullies. 中文 在几十年与各种规模的软件相关公司打交道的过程中，我学到的经验是，你们有一个人格和财务问题。 也就是说，很少有公司是由真正的工程师管理的。他们都是由数学家、律师、首席财务官、营销人员等管理。这些人并不 \"了解 \"程序员、工程师等。他们不喜欢他们，不理解他们，不与他们相处，甚至没有许多重叠的利益。反过来说也是大体如此。 例如，如果你去一家大型金融机构，你会发现C-Suite在28楼，可以看到水面上的风景，而构建运行公司的算法的IT人员则在某个地牢的无窗部分。或者，如果你去一家工程公司，工程师们将是开放式的，有垃圾灯、椅子、桌子和隔板，而高管们都有自己的独立办公室。 因此，高管们开始雇用与自己相似的人与 \"怪异 \"的工程师们 \"沟通\"。因此，像拥有PMP的PM、产品经理等就诞生了。 这些人在高管的压力下，以一种方式做事，而创造者确实应该以另一种方式做事。但这是一个等级制度。这不是一个谈判，这不是一个热衷于反馈的系统。高管们决定，工程师们应该执行。他们真的不喜欢工程师说这样的话：\"这个期限是不可能的。你可以选择快，也可以选择好，但你不可能两者兼得。\" 这就是那种会让高管发怒的事情。他们在季度计划中说他们要提供好的和便宜的，工程师怎么敢这么失败。最糟糕的高管们没完没了地抱怨，工程师们永远不会对涉及大量研发工作的事情给出一个合适的答案。他们开始喋喋不休地谈论无聊的事情，比如所有的未知数。同样，这位高管向董事会做了一个关于下一版本的产品如何以一半的成本拥有两倍的电池寿命的报告。难道整个工程部门都在密谋让他成为一个骗子？ 然后你有内部政治。这种事情甚至发生在一个柠檬水摊的层面上，但是一旦你有一个拥有100或100,000人的公司，政治就会统治行政层面。办公室政治的一个关键部分是控制信息。因此，你会得到一个绝对的规则，即工程类人员要尽可能远离客户。诸如项目要迟到这样的信息，几乎是任何管理层或更高层次的人都不愿意让任何其他管理层或更高层次的人知道的。 这种保密性使得那些抓狂的经理和高管们可以对工程师进行鞭打、威胁、做出空洞的承诺等，让他们在晚上、周末等时间工作，以达到一些虚假的目标，只是这些目标会让不同的高管获得数倍于工程师工资的奖金，然后他们会宽宏大量地带工程师去吃一大堆比萨饼或所有你能吃的自助餐。\"用公司的钱\"，这可能是20美元的工程师，而该经理在那个季度获得了5万奖金，主要是因为那些被宣扬为对公司忠诚和奉献的愚蠢的工程师。 但是，这一切的破绽在于，你有一些通常非常聪明的工程师、开发人员、研究人员等，他们发现自己被那些被赋予更高权力的人微观管理，但他们把责任丢给工程师。然而，工程师们不被允许与客户沟通，所以他们并不真正了解问题，他们得到了任意的最后期限。他们不能确定优先次序。最糟糕的是，那些通常是经理以上级别的人往往是白痴，因为这往往是一个BS工作，大多数有两个脑细胞的人都会拒绝。有时经理是前工程师，但这是整个彼得原则/失败的事情存在的地方。 即使在像NASA和波音这样巨大的 \"受人尊敬的 \"组织中，你也会听到工程师说的故事。如果你做了X，那么Y将被炸毁，并杀死很多人。然后一些经理推翻了他们，因为他们害怕对他们的上级说 \"不\"，等等，以满足一些任意的最后期限来建造一些东西，而建造这些东西的工程师对自上而下的设计没有任何意见，这些设计基本上是垃圾。 我所看到的，甚至怀疑存在于像美国国家航空航天局这样的地方的模式是，尽管有所有可怕的障碍，非常聪明的工程师还是成功了。他们没有良好的坚实的规划（不是纸上谈兵，而是实际的规划），他们可能是在一个又一个的火灾中战斗，同时在经理们不注意的时候把一些好的工程塞进项目中。 然后，就在任何工程师取得类似成功的时候，他们得到了一份工资单，并意识到项目经理的商业经验或教育程度比你的普通洗碗工要低，但确实得到了PMP，他的工资是他们的两倍。士气降到了零，现在你的工程师早上9点上班，下午5点下班，周末也不接电话了。不要告诉他们，50人的工程公司的首席执行官的旅行和娱乐预算是他们年薪的3到6倍，首席运营官的预算是3倍，首席财务官刚刚拿到公司支付的5万块钱的MBA，而他们却不能再花钱在城里用自己的时间参加周末课程，以获得公司在下一个项目中使用的关键技术的认证。 为什么会出现这样的差异？高管们是做出金钱决定的地方，而工程部门则不是。 有趣的一点是，我经常看到的是，那些非凡的开发人员、工程师等人的去处是为自己做生意。他们通常自己开发一些产品，而这些产品本来可以为公司带来数百万的收入，但他们自己做，而且通常根本没有雇用任何经理。他们的老公司甚至没有意识到他们失去了什么，因为那些撒谎和欺骗的经理和高管永远不会承认他们的错误，而只是责怪那些毫无防备的人，让剩下的工程师更加努力工作。 如果我不得不把它归结为一对线。 管理层通常讨厌工程人员，因为他们明显比管理层自己更聪明，更不容易支配；因此在他们的不安全感中，他们利用对财务的控制权来做正确的欺凌者。","link":"/%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98.html"},{"title":"绘制平滑的三次贝塞尔曲线","text":"基础知识 面临的问题 1. 选择二次贝塞尔曲线 or 三次贝塞尔曲线 2. 贝塞尔曲线控制点计算 问题分析 问题1： 问题2： 代码部分 基础知识# 阅读之前你需要知道的知识包括 canvas的坐标系 直角坐标中两点的中点公式 直角坐标中两点距离公式 基础的三角函数 投影基础知识 canvas绘制贝塞尔曲线 面临的问题# 1. 选择二次贝塞尔曲线 or 三次贝塞尔曲线# 2. 贝塞尔曲线控制点计算# 问题分析# 问题1：# 由于二次贝塞尔曲线绘制后，将只有一处弯曲，在多节点连接时，呈现效果很差。并且在45°，135°，225°，315°时，需要做特殊的处理，否侧得到的曲线的弧度过大。 问题2：# 在确定使用三次贝塞尔曲线后，需要通过计算得出曲线绘制时的两个控制点C1,C2。然后通过CanvasRenderingContext2D.bezierCurveTo进行绘制。 由于我们需要两个控制点，所以，我们将会把起点SP(start point)和终点EP(end point)间的连线S-E均分为4份。得到如下点： \\[ \\begin{align*} Split_{m} = (\\frac{(X_{SP}+X_{EP})}2,\\frac{(Y_{SP}+Y_{EP})}2)\\\\ \\end{align*} \\] 得到S-E的公式L(x)为 \\[ L(x) = \\frac{X_{Split_{m}}}{Y_{Slit_{m}}}x \\] 根据L(x)可知S-E的斜率满足 \\[ \\tan \\theta = \\frac{X_{Split_{m}}}{Y_{Slit_{m}}} \\] 然后将\\(Split_{m}\\)作为坐标系的原点，建立直角坐标系，得到 \\[ \\begin{align*} len = \\sqrt{(X_{Split_{m}}-X_{SP})^{2}+(Y_{Split_{m}}-Y_{SP})^{2}}\\\\ \\\\ \\theta = \\arctan \\frac{X_{Split_{m}}}{Y_{Slit_{m}}}\\\\ \\\\ Y_{offset} = len·\\cos \\theta \\\\ \\\\ C1=(X_{Split_{m}},Y_{Split_{m}}-len)\\\\ C2=(X_{Split_{m}},Y_{Split_{m}}+len) \\end{align*} \\] 代码部分# 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * @param props * @typeof props { start: number[]; end: number[]; canvas: CanvasRenderingContext2D; } */export const drawLine = (props: Common.LineProps) =&gt; { const { start, end, canvas: ctx, color } = props; const getMidCoord = (c1: number, c2: number) =&gt; { if (c1 === c2) { return c1; } return (c1 + c2) / 2; }; const [x1, y1] = start; const [x2, y2] = end; const [midX, midY] = [getMidCoord(x1, x2), getMidCoord(y1, y2)]; const drawMirror = (y1: number, y2: number) =&gt; { if (y1 &gt; y2) { return ctx.bezierCurveTo(control2[0], control2[1], control1[0], control1[1], end[0], end[1]); } else { return ctx.bezierCurveTo(control1[0], control1[1], control2[0], control2[1], end[0], end[1]); } }; const degCos = Math.cos(Math.atan((x1 - midX) / (y1 - midY))); const lineLen = Math.sqrt(Math.pow(y1 - midY, 2) + Math.pow(x1 - midX, 2)) * 2; const control1 = [midX, midY - degCos * (lineLen / 2)]; const control2 = [midX, midY + degCos * (lineLen / 2)]; ctx.beginPath(); ctx.moveTo(start[0], start[1]); drawMirror(y1, y2); ctx.lineWidth = 2; ctx.strokeStyle = color ? color : &quot;#000&quot;; ctx.stroke(); ctx.closePath();};","link":"/%E7%BB%98%E5%88%B6%E5%B9%B3%E6%BB%91%E7%9A%84%E4%B8%89%E6%AC%A1%E8%B4%9D%E5%A1%9E%E5%B0%94%E6%9B%B2%E7%BA%BF.html"},{"title":"通过服务器在指定时间将网页录制成视频","text":"通过服务器在指定时间将网页录制成视频# 为什么有这样的需求？ 我的目标 技术栈的选择 具体的实现方式 一、现行方案 该方案主要规避解决的问题： 核心流程 关键点： 方案性能（docker中） 二、尝试过的方案 getDisplayMedia模式 关键点 Q&amp;A 项目地址 为什么有这样的需求？# 笔者最近的工作在前端数据可视化领域，会出现一些对长时间运行的前端页面进行监控的需求。以往我的解决办法是通过一些现有的平台，在个人PC上通过浏览器进行录制，或者更早的方法是通过一些录屏工具进行录制。 在这样的方式中，经常会遇到以下问题： 分辨率不够还原 录制的日志格式难以解析 需要长期的打开个人电脑 通过平台录制的，往往不是视频，而是一段DOM-Mirror的记录。这样的记录很难分享给其他人进行问题排查 DOM-Mirror记录进行回放时，对于后端返回的实时数据渲染，缺少价值（因为当时的时间点已经错过了，回放时无法回放后端当时的服务状态） 并发录制个数受限于个人电脑的性能 录制后的文件不好管理 我的目标# So，基于上述的需求，我们需要达到以下的要求： 能在网页要求的原始分辨率情况下进行录制 能在服务端而不是个人电脑上进行录制 能录制通用的视频和日志文件，可以方便的分享给他人 能进行并发录制 视频帧数要足够流畅（至少4K下） 为录制的文件提供静态资源访问服务 技术栈的选择# 基础语言和框架——js&amp;nodejs 对于指定时间运行任务 —— cron job 对于打开网页 —— puppeteer 对于视频录制有以下备选方案 使用浏览器api getDisplayMedia进行录制 使用puppeteer按帧数截图，然后对图片用ffmpeg进行压制 使用xvfb将虚拟桌面的视频流直接通过ffmpeg进行编码录制 对于录制日志 —— puppeteer提供的devtools相关事件 对于并发处理 —— 引入加权计算 对于视频处理 —— ffmpeg 具体的实现方式# 一、现行方案# 该方案主要规避解决的问题：# 使用 getDisplayMedia时，受到浏览器的协议限制。这个api只在访问协议为https下可用，且音频的录制需要依赖其他的api。 getDisplayMedia的性能，在多网页并发录制时优化空间小，而且最致命的问题时，录制过程的性能开销，是由浏览器负担的。这意味着，如果页面本身对性能比较敏感，使用这个api基本无法录制出网页正常运行的情况。 puppeteer按帧数截图受到了chrome-devtools本身的限制，导致一秒只能截取出10+图。在数据可视化的场景中，大量的实时数据渲染，显然也是无法接受的。 核心流程# 关键点：# 使用node调用xvfb，创建虚拟桌面：开源库node-xvfb存在一些问题，创建的虚拟桌面，似乎共享了同一个流的缓冲区，在并发录制时，会出现抢占的情况，导致视频内容出现加速，所以需要封装一个新的node调用xvfb的功能 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394import * as process from 'child_process';class XvfbMap { private xvfb: { [key: string]: { process: process.ChildProcessWithoutNullStreams; display: number; execPath?: string; }; } = {}; setXvfb = (key: string, display: number, process: process.ChildProcessWithoutNullStreams, execPath?: string) =&gt; { this.xvfb[key] = { display, process, execPath, }; }; getSpecXvfb = (key: string) =&gt; { return this.xvfb[key]; }; getXvfb = () =&gt; this.xvfb; } const xvfbIns = new XvfbMap(); /** * 检测虚拟桌面是否运行 * @param num 虚拟桌面窗口编号 * @param execPath 内存缓冲文件映射路径 * @returns Promise&lt;boolean&gt; */ const checkoutDisplay = (num: number, execPath?: string) =&gt; { const path = execPath || '/dev/null'; return new Promise&lt;boolean&gt;((res, rej) =&gt; { const xdpyinfo = process.spawn('xdpyinfo', [ '-display', `:${num}&gt;${path}`, '2&gt;&amp;1', '&amp;&amp;', 'echo', 'inUse', '||', 'echo', 'free', ]); xdpyinfo.stdout.on('data', (data) =&gt; res(data.toString() === 'inUse')); xdpyinfo.stderr.on('data', (data) =&gt; rej(data.toString())); }); }; const getRunnableNumber = async (execPath?: string): Promise&lt;number&gt; =&gt; { const num = Math.floor(62396 * Math.random()); const isValid = await checkoutDisplay(num, execPath); if (isValid) { return num; } else { return getRunnableNumber(execPath); } }; export const xvfbStart = async ( key: string, option: { width: number; height: number; depth: 15 | 16 | 24 }, execPath?: string ) =&gt; { const randomNum = Math.floor(62396 * Math.random()); const { width, height, depth } = option; try { const xvfb = process.spawn('Xvfb', [ `:${randomNum}`, '-screen', '0', `${width}x${height}x${depth}`, '-ac', '-noreset', ]); xvfbIns.setXvfb(key, randomNum, xvfb, execPath); return randomNum; } catch (error) { console.log(error); return 99; } };export const xvfbStop = (key: string) =&gt; { const xvfb = xvfbIns.getSpecXvfb(key); return xvfb.process.kill();};export default xvfbIns; 服务器并发录制时进行负载均衡。这个功能是为解决并发录制视频编码时，服务器CPU的负载过高问题。所以为了尽可能的提高并发录制数量，我记录了每个服务器正在和将要执行的任务数量，将这个数量标记为服务的权重，当创建一个新的录制任务时，先检测当前服务器的权重，然后在权重最低的服务器上创建录制任务，并在录制完成和手动终止任务时，降低权值。 123456789101112131415161718192021222324252627282930313233import { CronJob } from 'cron';interface CacheType { [key: string]: CronJob;}class CronCache { private cache: CacheType = {}; private cacheCount = 0; setCache = (key: string, value: CronJob) =&gt; { this.cache[key] = value; this.cacheCount++; return; }; getCache = (key: string) =&gt; { return this.cache[key]; }; deleteCache = (key: string) =&gt; { if (this.cache[key]) { delete this.cache[key]; } this.cacheCount = this.cacheCount &gt; 0 ? this.cacheCount - 1 : 0; }; getCacheCount = () =&gt; this.cacheCount; getCacheMap = () =&gt; this.cache;}export default new CronCache(); 启动puppeteer时，需要提供一系列参数 12345678910111213141516171819202122const browser = await puppeteer.launch({ headless: false, executablePath: '/usr/bin/google-chrome', defaultViewport: null, args: [ '--enable-usermedia-screen-capturing', '--allow-http-screen-capture', '--ignore-certificate-errors', '--enable-experimental-web-platform-features', '--allow-http-screen-capture', '--disable-infobars', '--no-sandbox', '--disable-setuid-sandbox',//关闭沙箱 '--start-fullscreen', '--display=:' + display, '-–disable-dev-shm-usage', '-–no-first-run', //没有设置首页。 '–-single-process', //单进程运行 '--disable-gpu', //GPU硬件加速 `--window-size=${width},${height}`,//窗口尺寸 ], }); 方案性能（docker中）# 标准1k分辨率下：双核CPU 2.3Ghz; 4G ram下，并发数10个 标准2k分辨率下：双核CPU 2.3Ghz; 4G ram下，并发数4个 二、尝试过的方案# getDisplayMedia模式# 关键点# 该api的调用，会导致chrome弹出选择具体录制哪个网页的交互窗口。关闭这个窗口需要在启动puppeteer时启用以下参数 123456789'--enable-usermedia-screen-capturing',`--auto-select-desktop-capture-source=recorder-page`,'--allow-http-screen-capture','--ignore-certificate-errors','--enable-experimental-web-platform-features','--allow-http-screen-capture','--disable-infobars','--no-sandbox','--disable-setuid-sandbox', 执行录制时，需要通过puppeteer page.exposeFunction注入函数进行执行。 Q&amp;A# Q：为什么要引入xvfb？ A：在尝试的方案中，getDisplayMedia需要运行环境提供一个桌面环境。在现行方案中，则是需要把xvfb的视频流直接推入到ffmpeg中 Q：为什么对内存有一定要求？ A：提供chrome的最小运行内存 项目地址# https://github.com/sadofriod/time-recorder","link":"/%E9%80%9A%E8%BF%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9C%A8%E6%8C%87%E5%AE%9A%E6%97%B6%E9%97%B4%E5%B0%86%E7%BD%91%E9%A1%B5%E5%BD%95%E5%88%B6%E6%88%90%E8%A7%86%E9%A2%91.html"},{"title":"高性能分组列表设计(1)","text":"高性能分组列表设计 整体目标 分析 数据结构设计 算法选择 一维对象数组转换成嵌套结构设计： 具体实现 一维对象数组转换成嵌套结构实现： 高性能分组列表设计# 整体目标# 分组存在嵌套关系，且深度无理论上限 可以通过拖拽，将已分组元素拖出，接触分组关系 可以通过拖拽，将未分组元素拖入分组内，建立新的分组关系 未分组列表项移动时，会自动越过分组及其子组件 未分组列表项进行分组时，应保持分组前的相对顺序 已分组列表项，在解除分组时，应保持分组前的相对顺序 以上操作对直接操作分组时，也应有效（这里将分组也作为一个列表项进行操作） ## 分析 由于目标1&amp;5，数据结构应保持一维结构，即对象数组的形式。这样的数据结构，提供了列表项的基础顺序，方便在创建分组时保持列表项的相对顺序。 对于目标2&amp;3&amp;5&amp;6，在计算拖拽项是否建立/更新/删除分组关系时，应记录已分组列表项在组内的相对位置，方便在分组关系变化时，对列表的位置进行排序 对于目标7，应把分组也作为列表项之一。提供“type”字段作为分组列表项和其他列表的区别，为后续可能拓展分组的展开/收起功能 渲染列表时会使用一个多维结构的数据，方便递归的对列表进行渲染，对于jsx语法友好。 ## 数据结构设计 列表项数据结构 1234interface ListItem { code: string; groupCode: string;} 列表数据结构 1type List = ListImte[] 更新分组时的辅助数据结构 12345type GroupStack = { groupCode: string; index: number; // 分组真实的下标 offsetNumber: number // 分组的长度，方便记录分组内列表项的相对位置}[] 用于react渲染的数据结构 12345interface AssistStruct { code: string; children?: AssistStruct[]; parentGroupCode?: string; //pop stack flag} 算法选择# 一维对象数组转换成嵌套结构设计：# 检测分组闭合,算法属于括号闭合算法的变种。 使用栈记录，未闭合的分组code。当前列表项中的group-code字段与栈顶的code不相等时，表示分组闭合，并且弹出当前栈顶元素。 具体实现# 一维对象数组转换成嵌套结构实现：# 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990/** * 将一维数组转成多层结构 * @param compCodes 所有组件的code * @param compDatas 所有组件的数据 * @returns 返回和code相关的嵌套结构、 */const subList = (compCodes: string[], compDatas: JDV.State['compDatas']): AssistStruct[] =&gt; { let groupStack: GroupStack[] = []; const resultData: AssistStruct[] = []; const stackPop = (groupCode?: string) =&gt; { let len = groupStack.length - 1; while (len &gt;= 0) { if (groupStack[len].groupCode !== groupCode) { groupStack.pop(); } else { break; } len--; } }; const setResult = (result: AssistStruct[], groupStack: GroupStack[], groupCode: string, value: AssistStruct) =&gt; { groupStack.forEach((item, index) =&gt; { if (!result) { return null; } if (!result[item.index]) { return; } if (result[item.index].code !== groupCode) { // 如果当前组件的分组不等于结果中的key，向下搜索 return setResult(result[item.index].children as AssistStruct[], groupStack.slice(index + 1), groupCode, value); } else { if (result[item.index].children) { (result[item.index].children as AssistStruct[]).push(value); item.offsetNumber += 1; } else { result[item.index].children = [value]; } } }); }; compCodes.forEach((item, index) =&gt; { const hasGroup = compDatas[item] ? compDatas[item].config.groupCode : undefined; stackPop(hasGroup); if (compDatas[item].compCode === 'group') { if (hasGroup) { // 如果当前组件的父组件在栈顶,更新结果树 setResult(resultData, groupStack.slice(0), hasGroup, { code: item, children: [], }); //如果当前分组有父分组,此时分组栈一定不为空，分组索引为父分组长度-1 // debugger; groupStack.push({ groupCode: item, index: groupStack.length ? groupStack[groupStack.length - 1].offsetNumber - 1 : index, offsetNumber: 0, }); } else { groupStack = []; //没有分组，清空栈 resultData.push({ code: item, children: [], }); //如果当前分组没有父分组,此时分组栈一定为空，分组索引为结果长度 groupStack.push({ groupCode: item, index: resultData.length - 1, offsetNumber: 0, }); } } else { if (hasGroup) { // 如果当前组件的父组件在栈顶,更新结果树 setResult(resultData, groupStack.slice(0), hasGroup, { code: item, }); } else { groupStack = []; //没有分组，清空栈 resultData.push({ code: item, }); } } }); return resultData;","link":"/%E9%AB%98%E6%80%A7%E8%83%BD%E5%88%86%E7%BB%84%E5%88%97%E8%A1%A8%E8%AE%BE%E8%AE%A1-1.html"},{"title":"高性能分组列表设计-2","text":"通过改变列表项位置更新分组关系 要解决的问题 分析 实现 通过改变列表项位置更新分组关系# 要解决的问题# 移动分组时，分组所有的子项都要移动，且保持相对位置和关系不变 批量移动未分组列表项到分组内时，相对位置应不变 已分组列表项移动出分组范围时应，应解除分组关系 分析# 当分组移动时，所有分组的子项都不变，首先需要搜索到分组内所有的子项。然后记录该子项在分组内的相对位置，以及在整体列表中的位置。 这样在移动时，方便进行计算。 整体来讲，这个移动过程中的搜索部分将使用深度优先搜索的一种变种。移动后的排序，只需遵守搜索中分组和其子项的相对顺序遍历即可。 分组子项搜索流程如下： 1234567891011121314151617if (!groupCache.includes(hasGroup)) { //组件的分组不在查询的分组内。弹出所有的分组缓存 groupCache = []; return; } else { result.push(item); //组件的分组在分组缓存中 if (hasGroup !== groupCache[groupCache.length - 1]) { // 如果组件的分组不在缓存的顶层 const hasGroupCacheIndex = groupCache.indexOf(hasGroup); groupCache = groupCache.slice(0, hasGroupCacheIndex + 1); } if (compDatas[item].compCode === 'group') { // 组件本身是分组组件 groupCache.push(item); } } 列表项排序流程如下： 12345678910111213141516171819202122232425262728293031 /** * compDatas 所有的列表项{[code]:{ config: { [groupCode]:groupCode } } } * topLestSelectComps 和第一个要移动的列表项在同级的组件（处理批量移动的情况），数据结构与compDatas一致 * nearLowBoundsGroup 将要移动列表项所在的分组的下界，数据结构与compDatas一致 */ if (isToplest) { //如果移动位置在插入区间的顶部，表明组件在最外层 topLestSelectComps.forEach((item) =&gt; { result[item] = { newGroup: undefined, oldGroup: compDatas[item].config.groupCode }; return (compDatas[item].config.groupCode = undefined); }); return result; } if (nearLowBoundsGroup !== firstCompPrev) { //如果移动位置的下界的分组code不等于移动组件的code，则解除或更新分组关系 topLestSelectComps.forEach((item) =&gt; { if (item !== nearLowBoundsGroup) { result[item] = { newGroup: nearLowBoundsGroup, oldGroup: compDatas[item].config.groupCode }; compDatas[item].config.groupCode = nearLowBoundsGroup; } else { result[item] = { newGroup: compDatas[item].config.groupCode, oldGroup: compDatas[item].config.groupCode }; } }); return result; } return result;}; 实现# 分组子项查询详细代码 interface GroupConfigStruct { groupItemCode: string[]; } interface groupMapValueStruct { //分组内组件相对于分组索引的偏移量 offsetNumer: number; //分组的索引 currentIndex: number; } /** *根据分组关系排序一维数组 *@param compCodes 所有组件的code *@param compDatas 所有组件的数据 */ const sortListItem = (compCodes: string[], compDatas: JDV.State['compDatas']) => { const groupCodeCache = new Map(); const result: string[] = []; /** *递归的回溯当前分组的前驱分组，更新前驱分组的长度偏移量 *@param groupCode 分组组件的code *@param offsetNumber 分组长度的偏移量 */ const recursiveBacktracking = (groupCode: string, offsetNumber: number): null => { const parentGroupCode = compDatas[groupCode].config.groupCode; const belongGroup = groupCodeCache.get(groupCode) as groupMapValueStruct; groupCodeCache.set(groupCode, { //更新分组缓存，每此插入组件，偏移量+1 ...belongGroup, offsetNumer: belongGroup.offsetNumer + 1, }); if (parentGroupCode) { // 如果分组有父分组，回溯一步 return recursiveBacktracking(parentGroupCode, offsetNumber + 1); } else { return null; } }; compCodes.forEach((item, index) => { const group = compDatas[item].config.groupCode ? compDatas[item].config.groupCode : null; if (compDatas[item].compCode === 'group') { //如果组件是分组组件，将code推入分组缓冲内 groupCodeCache.set(item, { offsetNumer: 0, currentIndex: index }); } if (group) { //在分组内 if (groupCodeCache.has(group)) { // 组件的分组在缓存中 const belongGroup = groupCodeCache.get(group) as groupMapValueStruct; // 分组内组件插入的位置 const targetIndex = belongGroup.currentIndex + belongGroup.offsetNumer; result.splice(targetIndex + 1, 0, item); recursiveBacktracking(group, belongGroup.offsetNumer); } } else { result.push(item); } }); return result; }; export default sortListItem; 分组移动后排序详细代码 /** * 组件排序时处理分组的逻辑。 * @param compCodes 所有组件的code * @param compDatas 所有组件的数据 * @param code 当前组件code * @param destination 目标位置 * @returns result {Result} 返回组件排序后的分组关系，用于分组关系变化后，处理分组的尺寸。 */ export const groupResort = ( compCodes: string[], selectedCompCodes: string[], compDatas: JDV.State['compDatas'], destination: number ): Result => { const isToplest = destination === 0; const isBottomlest = destination + 1 === compCodes.length - 1; const lowBounds = isBottomlest ? compCodes.length - 1 : destination + 1; const interval = compCodes.slice(0, lowBounds); //插入区间 const intervalLastComp = compDatas[compCodes[lowBounds]]; const nearLowBoundsGroup = interval.find((item) => intervalLastComp && item === intervalLastComp.config.groupCode); //插入区间最下面的分组段 const firstCompPrev = compDatas[selectedCompCodes[0]] && compDatas[selectedCompCodes[0]].config.groupCode; // 第一个选中组件的分组 const topLestSelectComps = selectedCompCodes.filter((item) => compDatas[item].config.groupCode === firstCompPrev); // 和第一个选中在同级的所有选中组件 const result: Result = {}; if (isToplest) { //如果移动位置在插入区间的顶部，表明组件在最外层 topLestSelectComps.forEach((item) => { result[item] = { newGroup: undefined, oldGroup: compDatas[item].config.groupCode }; return (compDatas[item].config.groupCode = undefined); }); return result; } if (nearLowBoundsGroup !== firstCompPrev) { //如果移动位置的下界的分组code不等于移动组件的code，则解除或更新分组关系 topLestSelectComps.forEach((item) => { if (item !== nearLowBoundsGroup) { result[item] = { newGroup: nearLowBoundsGroup, oldGroup: compDatas[item].config.groupCode }; compDatas[item].config.groupCode = nearLowBoundsGroup; } else { result[item] = { newGroup: compDatas[item].config.groupCode, oldGroup: compDatas[item].config.groupCode }; } }); return result; } return result; };","link":"/%E9%AB%98%E6%80%A7%E8%83%BD%E5%88%86%E7%BB%84%E5%88%97%E8%A1%A8%E8%AE%BE%E8%AE%A1-2.html"},{"title":"数组中k个数的最大偶数和","text":"题目# 长度为m的数组，是否存在k个数的和为偶数，且和为最大和。 example： 12345678input: [123,12,424,32,43,25,46] 4;output: 636;input:[1000] 2;output:-1input: [1,3,5,7,9] 3;output: -1 分析过程# 首先判断数组M的长度是否小于k，如果小于k，则直接返回-1。 如果数组长度不小于k，则对现有数组进行排序，取排序结果N的前k位的和。判断当前k个数的和是否是偶数，如果是，返回当前和。如果不是，则循环判断排序N-K~N位置中是否存在一个数，使得结果成立。 ps：这里只判断是否存在一个数是因为，当最大和存在，但不为偶数的情况成立，则k mod 2 ≠ 0且构成N的数都为奇数。 排序方式# 将数组的第Q项作为基准项（基准项为base。这里将Q取为0，但事实上，用任意一项都可以）。判断M[i]（0&lt;＝i&lt;M）是否大于base，如果大于，则替换base与M[i]值的位置，调换之后，遍历i-1～0（M的子数组subM，该数组已经是有序数组），将M[i]的值插入到subM中。如果小于等于，base＝M[i]。 逻辑结构# 排序的过程是按照中序遍历创建一颗二叉树，只要树的最左子树的节点个数等于k，则这个子树就是数组的最大和。如果最大和不是偶数，则按照中序遍历的规则，顺序寻找上层子树的节点是否存在可以满足的值。 代码# 12345678910111213141516171819202122232425262728293031323334353637383940const result = (test, k) =&gt; { let base = test[0]; let sum = 0; let tempK = 0; let sort = 0; let tempOutside = 0; let tempInside = 0; let baseIndex = 0; if (k &gt; test.length) { return -1; } for (let index = 1; index &lt; test.length; index++) { const element = test[index]; if (element &gt; base) { tempOutside = test[index]; test[index] = base; test[baseIndex] = tempOutside; for (let j = index - 1; j &gt;= 0; j--) { if (element &gt; test[j]) { tempInside = test[j]; test[j] = test[j + 1]; test[j + 1] = tempInside; } } } else { base = test[index]; } baseIndex++; } while (tempK &lt; k) { sum += test[sort]; if (tempK === k - 1 &amp;&amp; sum % 2 !== 0) { sum -= test[tempK]; tempK--; } tempK++; sort++; } return sum;};","link":"/algorithm/%E6%95%B0%E7%BB%84%E4%B8%ADk%E4%B8%AA%E6%95%B0%E7%9A%84%E6%9C%80%E5%A4%A7%E5%81%B6%E6%95%B0%E5%92%8C.html"},{"title":"在TS中使用字符串作为索引访问对象","text":"场景 &amp; 问题# 在访问对象的成员变量时，经常会用到使用字符串作为索引。在JS中，这样的用法是可以的。但是在TS中，当被访问的对象被赋予类型之后，这样的操作将会抛出异常，示例如下： ## JS中 123456789101112const testObj = { key1: 1, key2:2};// 获得存有当前对象所有Key（浅层）的一个数组 [&quot;key1&quot;，&quot;key2&quot;]const tempKeys = Object.keys(testObj); tempKeys.forEach((item)=&gt;{ // 正常输出testObj中的值 console.log(testObj[key]); }); 上述代码将输出我们预期的结果。 TS中# 12345678910111213141516171819202122232425262728interface TestObjType { key1:number; key2:number;}const testObj:TestObjType = { key1:1, key2:2}type tempKeysType = keyof TestObjType// 获得存有当前对象所有Key（浅层）的一个数组 [&quot;key1&quot;，&quot;key2&quot;]const tempKeys = Object.keys(testObj) as Array &lt;keyof TestObjType&gt;; //这里将会有一个报错，提示 ://参数“item”和“value” 的类型不兼容。`不能将类型“string”分配给类型“&quot;key1&quot; | &quot;key2&quot;”.//这表明了，即使tempKeysType是通过keyof 从TestObjType中获取到的，但是forEach的callback的参数类型，仍然无法通过TS的类型兼容性检查。tempKeys.forEach((item:tempKeysType)=&gt;{ //这里也会有一个报错：Element implicitly has an 'any' type because expression of type 'any' can't be used to index type 'TestObjType'。// TS的类型推断，表示item存在隐式的any类型，而any类型在TS中无法作为obj的索引。同样这也表示了在进行对象的遍历时（在当前代码片段中），不能将any作为item的类型，去访问对象 console.log(testObj[key]); });tempKeys.forEach((item:string)=&gt;{ //这里会有同样报错 console.log(testObj[key]); }); 解决思路# 对于这一问题的出现，猜测可能是由于在 1const tempKeys = Object.keys(testObj) as Array &lt;keyof TestObjType&gt;; 但此时可以看到，tempKeys的类型已经变成了 1(&quot;key1&quot;|&quot;key2&quot;)[] 所以问题很可能是由 Object.keys的默认值导致的。 由此可得如下解决方案 解决方案# 对于此问题，需要封装一个新的 keys 函数来解决 123456789101112131415161718192021// 新的keys函数，使用O继承objectfunction keys&lt;O extends object&gt;(obj: O): Array&lt;keyof O&gt; { return Object.keys(obj) as Array&lt;keyof O&gt;;}interface TestObjType { key1:number; key2:number;}const testObj:TestObjType = { key1:1, key2:2}type tempKeysType = keyof TestObjType// 使用新的keys获得存有当前对象所有Key（浅层）的一个数组 [&quot;key1&quot;，&quot;key2&quot;]const tempKeys = keys(testObj) ; tempKeys.forEach((item:tempKeysType)=&gt;{ console.log(testObj[key]); }); 上述代码将输出我们预期的结果。","link":"/typescript/typescript.html"},{"title":"在React Native中函数式的控制Loading Component","text":"阅读前你需要知道的 为什么需要函数式的控制Loading Component 要解决的问题 实现 设计思路 代码 阅读前你需要知道的# React Context是什么 如何自定义Hooks # 为什么需要函数式的控制Loading Component 在APP的开发中，我们经常会遇到一些异步的操作，比如通过网络请求获取数据。在用户进行这类操作的时候，一般需要弹出一些提示的组件，用来表示这次网络请求所处的状态。 最简单的实现方法是维护一个内部State，在网络请求的状态发生变化的时候，按照业务需求同步更新这个内部状态，并且根据这个状态来决定Loading Component是否渲染，代码示例如下 12345678910111213141516171819const TestLoading = () =&gt; { const [isError, setIsError] = useState(false) const handleRequest = async () =&gt; { try { await requestAPI() setIsError(false) }catch(e){ setIsError(ture) } } return ( &lt;&gt; &lt;Button title='request' onPress={handleRequest} /&gt; &lt;Modal visible={isError}&gt; &lt;ActivityIndicator size=&quot;large&quot;/&gt; &lt;/Modal&gt; &lt;/&gt; )} 从上面的代码我们不难看出，如果使用和这种简单的实现方式，需要在每个需要展示Loading Component的页面，手动添加它，并且还需要增加一个内部状态来控制它的展示。这不免显得有些冗余，如果过我们可以使用如下的函数式的调用方式来控制Loading Component，将大量减少冗余代码 123456789101112const TestLoading = () =&gt; { //... const handleRequest = async () =&gt; { showLoading() await requestAPI() closeLoading() } //... return ( &lt;Button title='request' onPress={handleRequest} /&gt; )} 要解决的问题# 和web不同的是，在Mobile的开发中，我们无法直接调用类似UIView这类的原生方法来增加新的Element 保持最大的兼容性，尽量不依赖Mobile平台提供的特殊API # 实现 ## 设计思路 对于这样的Loading Component在整个APP中可以只存在一个这样的组件，并将它在APP的最外层进行挂载，然后在通过React Context共享它的控制渲染的函数。这样，我们就可以在任意一个组件或者Hook中控制Loading Component了。 ## 代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// GlobalLoaidngProvider.tsxexport const GlobalLoadingContext = React.createContext({ show: console.log close: console.log});export const GlobalLoadingProvider: React.FC&lt;React.PropsWithChildren&gt; = ({ children}) =&gt; { const [isShow, setIsShow] = useState(false); const [message, setMessage] = useState(''); const handleShow = (message?: string) =&gt; { setIsShow(true); message &amp;&amp; setMessage(message); } const handleClose = () =&gt; { setIsShow(false) } return ( &lt;GlobalLoadingContext.Provider value={{ show: handleShow, }}&gt; {children} &lt;Modal animationType=&quot;slide&quot; transparent={true} visible={modalVisible} &gt; &lt;ActivityIndicator size='large' /&gt; &lt;Text&gt;{message}&lt;/Text&gt; &lt;/Modal&gt; &lt;/GlobalLoadingContext.Provider&gt; )}// App.tsx// ...const App = () =&gt; { //... return ( &lt;GlobalLoadingProvider&gt; {//... you component} &lt;/GlobalLoadingProvider&gt; )}//RequestAPIButton.tsxconst RequestAPI = () =&gt; { const {show, close} = useContext(GlobalLoadingContext) const handleRequest = async () =&gt; { show(&quot;data lading&quot;); await requestAPI(); close(); }; return( &lt;Button onPress={handleRequest} title=&quot;requestAPI&quot; /&gt; )}","link":"/%E5%9C%A8React%20Native%E4%B8%AD%E5%87%BD%E6%95%B0%E5%BC%8F%E7%9A%84%E6%8E%A7%E5%88%B6Loading%20Component.html"}],"tags":[{"name":"project","slug":"project","link":"/tags/project/"},{"name":"interesting","slug":"interesting","link":"/tags/interesting/"},{"name":"error","slug":"error","link":"/tags/error/"},{"name":"interestring","slug":"interestring","link":"/tags/interestring/"},{"name":"algorithm","slug":"algorithm","link":"/tags/algorithm/"},{"name":"typescript","slug":"typescript","link":"/tags/typescript/"}],"categories":[{"name":"project","slug":"project","link":"/categories/project/"},{"name":"interesting","slug":"interesting","link":"/categories/interesting/"},{"name":"error","slug":"error","link":"/categories/error/"},{"name":"algorithm","slug":"algorithm","link":"/categories/algorithm/"},{"name":"typescript","slug":"typescript","link":"/categories/typescript/"}],"pages":[]}